UTILS:CHEAT SHEET by GV
.I https://www.gnu.org/software/coreutils/manual/html_node/index.html#Top
.I https://www.gnu.org/software/coreutils/manual/html_node/tac-invocation.html#tac-invocation 

------------------------------------------------------------------------------------------------------------------------

UTILS:FILE MANIPULATIONS
Depending on the job you can use different commands:

.SY "Synopsis of Commands"
cut file: slices a line of file (or multi lines) based on a delimiter.
paste file1 file2: Prints field of both files side by side , ignoring matching criteria
diff file1 file2 : Prints differences of files 
sort file1 file2 fileN: Sorts the files. Can be adjusted to sort on a specific columnt (i.e 1.2 = file 1 column2)
join file1 file2 : Joins files in a common field
.YS #end of synopsis

------------------------------------------------------------------------------------------------------------------------
UTILS:MAN PAGES & CHEAT SHEETS 

##CHEAT SHEET TXT 2 MANPAGE FORMATTING

.B man pages making & groff programming 
.I http://technicalprose.blogspot.gr/2011/06/how-to-write-unix-man-page.html
.I https://man7.org/linux/man-pages/man7/groff_man.7.html
.I https://man7.org/linux/man-pages/man7/groff_man_style.7.html
.I https://liw.fi/manpages/
.I https://linux.die.net/man/1/help2man
.I http://web.cecs.pdx.edu/~trent/gnu/groff/groff.html#IDX123

.OP "$ man 7 man" 
.OP "$ man 7 man-pages"

Package 'help2man' creates man pages with groff formating from the --help output of an executable command.
.I man <(help2man grep)
Use just 'help2man grep' to see on screen how help2man formats the man page by the help section of a command with groff.

Tip: To see which programs does not provide a man page use the command 'manpage-alert' from deb devscripts.
manpage-alert will scan the bin directories (i.e /usr/bin) and check if a man page exists for each executable located in bin locations.

Tip: help2man fails if an error occured (i.e some bins do not run as root). You can avoid this failure using --no-discard-stderr flag like this:
.I man <(help2man --no-discard-stderr icedove)


.B See the special synthax of any installed man page
    zcat manpage.gz
    zcat $(man -w grep)


.B WORKING COMMAND:
man --nj <(h=".TH man 1 2017 1.0 cheats page";sed "1i $h" cheatsheets/utils*gv.txt |sed 's/^UTILS:/.SH UTILS:/g; s/^$/\.LP/g; s/^##/\.SS /g; s/\\/\\e/g;G' |sed 's/^$/\.br/g')
You can also combine with --nh 
PS: man options --nj = not auto justified , --nh = not auto break words with hyphen on line changes.

##MAN AND GROFF/troff FORMATING - groff /troff require special handling.
man ignores normal line feeds at end of lines ($); empty lines (^$) are recognized and displayed
Line feeds in man pages can be done by inserting .br between two lines.
More .br in series of lines are ignored by man and got intepreted as a single line feed - not multiple new lines.
Man pages should start with a .TH line
Man sections / header start with .SH. 
Subsection start with .SS. All the sections in this document starting with ## are changed to .SS

Bold Line: Use .B to make this line bold. .B follows text identation - .SS has it's own idents.
The backslash \ works as escape in groff, so you need to escape the backslash with \e (or \\ can also work)
The example tr -d '\n' will become tr -d '\en' with \e escaping, or will become tr -d '\\n' with \\ escaping.
.SY "More Commands"
\.B  : Bold , should be inserted in the beginning of the line.
\.I  : Italic, usually different color - at line start only
\.SY : Synopsis Section. After .SY the Title is added - Next lines are idented automatically under synopsis. .SY section ends with an empty line or with .YS
\.TH : Title Heading , single word - no spaces recognized.
\.OP : Command line Option - recognizes commands i.e .OP cat file1 will appear as [cat file1] but the rest word (i.e #comments) are ignored.
.YS

##MAN - SEE MANPAGES OF NON INSTALLED PACKAGES USING CURL (see also manon shell script)
You can either decompress a .deb in the screen and ask man to display it OR
you can download the .deb package and decompress/display the manpages available and finally delete the .deb unless you plan to tinstall it!

.I On line - No deb download
$ apt --print-uris download agrep
'http://ftp.gr.debian.org/debian/pool/non-free/a/agrep/agrep_4.17-9_amd64.deb' agrep_4.17-9_amd64.deb 194788 SHA256:4d3648e483f9a367b821095c9d6e24016b486723920e4abc34324ad1c89f2867
$ curl -sL -o- 'http://ftp.gr.debian.org/debian/pool/non-free/a/agrep/agrep_4.17-9_amd64.deb' |dpkg -c /dev/stdin  --> Provides a list of all the contents inside deb
$ curl -sL -o- http://ftp.gr.debian.org/debian/pool/non-free/a/agrep/agrep_4.17-9_amd64.deb |dpkg-deb --fsys-tarfile /dev/stdin|tar -t  --> Also provide a list of deb contents

$ curl -sL -o- http://ftp.gr.debian.org/debian/pool/non-free/a/agrep/agrep_4.17-9_amd64.deb |dpkg-deb --fsys-tarfile /dev/stdin|tar -xO ./usr/share/man/man1/agrep.1.gz |man /dev/stdin

The use of dpkg-deb --fsys-tarfile is required since deb packages when unzipped are constisted of two major subfiles.

.I With downloading deb package
$ apt download agrep            ---> Get:1 http://ftp.gr.debian.org/debian jessie/non-free amd64 agrep amd64 4.17-9 [195 kB]
OR 
$ curl -sLO "http://httpredir.debian.org/debian/pool/main/a/avis/avis_1.2.2-4_all.deb" # curl -O saves the file in CWD

$ dpkg -c $(ls *.deb)                          ---> prints contents of data.tar inside deb file on the screen
$ dpkg-deb --fsys-tarfile $(ls *.deb) |tar -t  ---> also prints data.tar content on the screen
$ dpkg-deb --fsys-tarfile $(ls *.deb) |tar -xO ./usr/share/man/man1/agrep.1.gz |man /dev/stdin -->display the man page correctly on screen

OR
ar -t "$(ls *.deb)"  --> Lists the main packages of the deb wrapper (data.tar.gz/xz , control.tar.gz/xz , debian-binary)
ar -p "$(ls *.deb)" data.tar.gz |tar -zt  --> Listing files . data.tar coule be gz (like agrep) or .xz (in this case we need tar -Jt)
ar -p "$(ls *.deb)" data.tar.gz |tar -xzO ./usr/share/man/man1/agrep.1.gz |man /dev/stdin   --> works ok

##MAN PAGES FOR INTERNAL BASH BUILTIN COMMANDS
if you try man readarray you get nothing.
man is used to display help pages of external (out of bash) tools, like man grep
To display a short man page of a builtin command you need to run help -m readarray.

To identify if a command is internal or external , use type:
$ type readarray
readarray is a shell builtin

$ type grep
grep is /bin/grep

##MAN PAGES IN COLOR
https://www.tecmint.com/view-colored-man-pages-in-linux/

$ vi ~/.bashrc
export LESS_TERMCAP_mb=$'\e[1;35m'
export LESS_TERMCAP_md=$'\e[1;35m'
export LESS_TERMCAP_me=$'\e[0m'
export LESS_TERMCAP_se=$'\e[0m'
export LESS_TERMCAP_so=$'\e[01;33m'
export LESS_TERMCAP_ue=$'\e[0m'
export LESS_TERMCAP_us=$'\e[1;4;31m'

Color codes used in the above configuration.
31 – red (secondary options)
35 – Magenta (titles & main options)
33 – yellow (footer & search)

Escape codes used in the above configuration.
0 – reset/normal
1 – bold
4 – underlined

##MAN PAGES IN VIM
viman () { man "$@" >/dev/null 2>&1 && man "$@" | vim -R +":set ft=man" - ; }
Tip: 
You can then save the man page as it is displayed on screen (like a normal text and not groff file) using 
:w filename

##CHEAT SHEETS & MAN PAGES ALTERNATIVES
https://www.ostechnix.com/3-good-alternatives-man-pages-every-linux-user-know/

.B BROPAGES                 http://bropages.org/
gem install bropages        #Requires Ruby
bro find                    #return usage examples

.B CHEAT                    https://github.com/chrisallenlane/cheat
pip install cheat           #Requires Python
cheat find              #Returns usage examples and cheats
cheat list              #List of available cheat sheets
cheat -h                    #Help

.B TLDR PAGES               https://github.com/tldr-pages/tldr
npm install -g tldr         #Requires NodeJS
tldr find                   #Returns usage examples
tldr --update               #TLDR can be updated
tldr --list-all         #See all cheat sheets in cache

.B MANLY                    https://github.com/carlbordum/manly
pip install manly           #Python
manly grep -o               #Returns man page part specific for the flag provided (-o in this case)
manly find -path
manly --help

.B CHEAT.SH PAGE                https://github.com/chubin/cheat.sh
curl cheat.sh/grep              # grep examples
curl cheat.sh/~screenshot       # searching for screenshot
curl cheat.sh/rust/hello        # hello world program in rust. 
curl cheat.sh/scala/~currying   # look for currying in scala cheat sheets
curl cheat.sh/~snapshot/r       # look for snapshot in all cheat sheets
.I Special pages:
    :help               help page
    :list               list all cheat sheets
    :post               how to post new cheat sheet
    :bash_completion    bash function for tab completion
    :bash               bash function and tab completion setup
    :fish               fish function and tab completion setup
    :zsh                zsh function and tab completion setup
    :emacs              cheat.sh function for Emacs
    :emacs-ivy          cheat.sh function for Emacs (uses ivy)
    :styles             list of color styles
    :styles-demo        show color styles usage examples


.B PINFO                    https://github.com/baszoetekouw/pinfo
An alternative infopages viewer/browser
apt-get install pinfo
pinfo sed                   #call sed infopage from /usr/share/info/sed.info.gz
pinfo -m sed                #use manual page instead infopage. Default action when infopage is not available.

info files look like: /usr/share/info/wget.info.gz
Locate available info pages: ls -l /usr/share/info/*
Infopages locations:  /usr/share/info,  /usr/info,  /usr/local/share/info,  /usr/local/info.   and  /opt/info.

Navigate inside infopage using arrows (up/down to scroll, right to enter a submenu, left to go back)

Tip:
zcat /usr/share/info/sed.info.gz |less   will display the whole info page at once. You can make regex searches using /

#-----------------------------------------------------------------------------------------------------------------------
UTILS:DEB - TAR FILES
Extract any compressed text file from downloaded deb:
apt-get download netcat
ar -p `ls *.deb` data.tar.xz |tar -Jt  #list files 
ar -p `ls *.deb` data.tar.xz |tar -xJO ./usr/share/doc/netcat/changelog.Debian.gz |gunzip |cat (or less or whatever)
OR
ar -p `ls *.deb` data.tar.xz |tar -xJO ./usr/share/doc/netcat/changelog.Debian.gz |man /dev/stdin (man does unzip!)

for some reason tar fails to unzip the last gz file (but gunzip works ok):
ar -p `ls *.deb` data.tar.xz |tar -xJO ./usr/share/doc/netcat/changelog.Debian.gz |tar -xzO |cat

if the file is not compressed you can just run tar -O (output to stdout = screen)
ar -p `ls *.deb` data.tar.xz |tar -xJO ./usr/share/doc/netcat/copyright

curl -sL -o- "http://ftp.gnu.org/gnu/tar/tar-latest.tar.gz" |tar -tz --wildcards --no-anchored '*.h'   #archive file listing with wildcards - avoiding grep
curl -sL -o- "http://ftp.gnu.org/gnu/tar/tar-latest.tar.gz" |tar -zt |grep '/src/.*\.h$'               #classic tar archive file listing
curl -sL -o- "http://ftp.gnu.org/gnu/tar/tar-latest.tar.gz" |tar -xzO --wildcards --no-anchored '*.h'    #extract and dump contents on screen
curl -sL -o- "http://ftp.gnu.org/gnu/tar/tar-latest.tar.gz" |tar -xzf - --wildcards --no-anchored '*.h'  #extract and save files locally in a new directory tar-1.29 (goes into CWD)
curl -sL -o- http://ftp.gr.debian.org/debian/pool/non-free/a/agrep/agrep_4.17-9_amd64.deb |dpkg-deb --fsys-tarfile /dev/stdin|tar -t # Displays files in deb archive, identical to dpkg -c


$ curl -sL -o- "https://github.com/fhcrc/seqmagick/archive/0.6.1.tar.gz" |tar -zt  --> listing of tar archive files
$ curl -sLO "https://github.com/fhcrc/seqmagick/archive/0.6.1.tar.gz"; ls -l *.tar.gz
-rw-r--r-- 1 root root 672141 Apr  3 11:37 0.6.1.tar.gz
$ tar -tf 0.6.1.tar.gz ---> Listing of the archive files of the saved tar

Tip: Using always -L ensure that curl will follow moved links to their new location. For example bellow command fails without -L:
$ curl -o- "https://github.com/fhcrc/seqmagick/archive/0.6.1.tar.gz"
<html><body>You are being <a href="https://codeload.github.com/fhcrc/seqmagick/tar.gz/0.6.1">redirected</a>.</body></html>



#-----------------------------------------------------------------------------------------------------------------------
UTILS:GREP

##EXCLUDE FROM ONE FILE ENTRIES THAT EXIST IN ANOTHER FILE: grep -Fxvf file2.txt file1.txt
-F for fixed string in order to avoid regex =fgrep (with regex an entry "tar" in file2 will match tar,patar, guitar, etc in file1) 
-x = line grep to ensure matching whole lines 
-v = reverse the grep = display not matching lines
-f = load words/lines from file file2.txt
-E = extended regex = egrep
file1.txt = the file to be grepped 
Tip: egrep and fgrep are actually shell scripts that call grep -E and grep -F respectivelly

##MULTI GREP WITH REVERSE OPERATION : grep -v -e "pattern" -e "pattern"
grep -nA1 -e "====" c.txt |grep -B1 -e "====" |grep -v -e ":" -e "--"

##GREP ALL FILES FOR TWO PATTERNS (and operation)
http://stackoverflow.com/questions/41896604/linux-listing-files-that-contain-several-words#41897079
grep -ERl 'toto' | xargs -r grep 'tata'
Tip : xargs -r ensures that second grep will not run in null / non matched data.
Alternative : awk '/pattern1/&&/pattern2/'

##GREP A FILE FOR TWO PATTERNS WITH AGREP BY CHAZELAS:
http://unix.stackexchange.com/questions/55359/how-to-run-grep-with-multiple-and-patterns/55391#55391
agrep 'pattern1;pattern2' file (can also accept pattern3;patternN)
grep -X '.*pattern1.*&.*pattern2.*'
grep -P '^(?=.*pattern1)(?=.*pattern2)'
grep -e 'pattern1.*pattern2' -e 'pattern2.*pattern1'
Alternatives:
awk '/pattern1/ && /pattern2/'
awk '/regexp1/ && /regexp2/ && /regexp3/ { print; }'

##GREP COLORIZE 
.I grep --color 'pattern' file
This will return and colorize ONLY the matching lines. 
Colorize will be applied only to 'pattern' and not to the whole line, unless we use 'pattern.*' or '.*pattern.*'

.I grep --color -E 'pattern.*|$' file
This will print ALL lines of the file but will colorize only the lines matching pattern
This works because |$ (or |^) matches and colorize invisibly the null byte at the end of the line (or at the beginning in case of |^)

.I In a function: 
function highlight () { grep --color -E "$1|$" "${@:1}" }

.I Retain Color when piped (i.e to less)
grep --color=always 'pattern' file |less -r #or -R.
color auto enables colors when destination of output is a tty but on a pipe color marking (esc sequences) are removed.
Using --color=always color sequences are retained even in pipes. less is forced due to -r or -R to read those coloring instructions

.I Colorize but also print the non matching lines along with matching lines
grep --color -E 'pattern|$' file #or '^|pattern'

##GREP MULTIPLE PATTERNS AND PRINT
Combine grep with cut and multipatterns: 
instead of grep |cut combination you can use awk
grep -E 'Label 3 \|Label 5' |cut -d' ' -f3 <==> awk '/Label 3/ { print $3 } /Label 5/ { print $3 }'
PS: AWK can directly print to a file using { print $3 >>"F3.csv" } 

##GREP AN HTML LINK FROM A STREAM
stream=...\f4 HYPERLINK "httjps://archive.org/randomURL1?fref=grp_mmbr_list"}...
grep -Eo '\"https?:\/\/[^"]+\"' testsample.txt 

##GREP ALL CHARACTER BEFORE THE FIRST WHITESPACE USING GREP?
grep -oP "^\S+" filename.txt

##GREP USING A FILE WITH PATTERNS.
Generally you can import patterns by a file using the -f switch.
Also you can feed the -f with process substitution to feed grep with manipulated patters grep -f <(cut -f2 patterns.txt) a.txt
In more tricky usage you can use the same file as file pattern in order to achieve complex grep results.
For example: 
grep -v -f <(grep "ok" a.txt |cut -d' ' -f1) a.txt
This will search the file a.txt for a second column having a text ok and will get the names marked as ok.
Then these names will be the main pattern to grep and exclude them from the whole,same file
Obviously this is usefull if on the master file a.txt not all the names have ok , but indirectly even if one ok is present for a user, you want to exclude this user from all the results.

##GREP COMBINED WITH FIND
find . -type f -exec grep pattern {} +
grep -r pattern /the/dir
find . -type f -print0 | xargs -r0 grep pattern
LC_ALL=C grep -r pattern .

##GREP MULTIPLE FILES IN PARALLEL:
http://unix.stackexchange.com/questions/197352/how-to-start-multi-threaded-grep-in-terminal
find . -type f -print0  | xargs -0 -P number_of_processes grep mypattern > output #Use find to get the files, invocating xargs in parallel mode.
find . -type f | parallel -j+1 grep mypattern #use the parallel utility
find ./appsfiles/ -type f | parallel -k -j200% -n 2000 -m grep -H -n -e "Exec=" -e "Comment" -e "Generic" -e "Name" {}
PS1: by timing above find |parallel vs a single grep yeld same results on 5000 desktop files.
PS2: This gives 50% MORE time than single grep : time find ./appsfiles/* -type f -print0 | xargs -r0 -P2 grep -H -n -e "Exec=" -e "Comment" -e "Generic" -e "Name" {}

##GREP REGEX OR
grep -E '^([a-z]{1,3}|pom.|i,j,k)$' b.txt
match lines with one word, that have less than 4 letters a-z , and also catch word 'pom.' and 'i,j,k'
can be used as -Eow to match words in a line
Tip: grep -E = extended regex , treats pipe symbol as an OR. Classic grep can use this OR by escaping the pipe symbol : grep 'patt1\|patt2'. 

##GREP PCRE Lookahead/lookbehind
https://www.regular-expressions.info/lookaround.html

.I Negative lookbehind: 
(?<!a)b   ---> matches "b" that is not preceded by an "a", using negative lookbehind. 
It doesn't match cab, but matches the b (and only the b) in bed or debt. 

.I Positive lookbehind :
(?<=a)b   ---> matches the b (and only the b) in cab, but does not match bed or debt since there is not an "a" before "b".

.I Negative lookahead: 
q(?!u). matches a "q" that is not followed by an "u" without matching u itself
echo "quit qax" |grep -P 'q(?!u)'   ---> quit qax
                                              ^ 
.I Positive lookahead :
q(?=u) matches a "q" only if is followed by an "u", without making the u part of the match. 
echo "quit qax" |grep -P 'q(?=u)'    ---> quit qax
                                          ^
.I More complex examples 

$ echo "baba cab bed debt" |grep -P '(?>a)b'    ---> baba cab bed debt --- seems equal to 'ab' pattern
                                                      ^^   ^^
$ echo "bara cab bed debt" |grep -P 'b(?>a)'    ---> bara cab bed debt  --- seems equal to 'ba' pattern
                                                     ^^   
$ echo "one two three" |grep -Po '(?=two).*'    ---> two three

$ echo "one two three" |grep -Po '(?<=two).*'   ---> three

$ echo "one two three" |grep -Po '.*(?=two)'    ---> one 

$ echo "one two three" |grep -Po '.*(?<=two)'   ---> one two

$ echo "one two three" |grep -Po '(?:two).*'    ---> two three

$ echo "one two three" |grep -Po '.*(?:two)'    ---> one two

$ echo abc_12345678.csv | grep -oP '(?<=_)\d+(?=\.)' ---> 12345678

##GREP FORGET PREVIOUS :
\K: This sequence resets the starting point of the reported match. Any previously matched characters are not included in the final matched sequence.

$ grep  'sda:' /var/log/messages.1
Mar 10 03:37:14 debian kernel: [    7.122304]  sda: sda1 sda2 sda3 sda4 < sda5 sda6 >

$ cat /var/log/messages.1 |grep -Po 'sd[a-z]+: \Ksd[a-z0-9].*'
sda1 sda2 sda3 sda4 < sda5 sda6 >

$ a="Configuration file 'hello2. conf' is in use by process 735." && echo "$a" |grep -Po 'process \K[0-9]*'
735 (https://regex101.com/r/hxwGPA/1)

##GREP Lookahead - Capture part of text between two patterns (requires -P = Perl Regex support)
$ echo "$a"
user    25999  0.0  0.7 678772 259772 ?       Ssl  Nov05  11:54 fwd
$ echo "$a" |grep -Po '.* \K\w+ (?=[?])'
259772   #---> Result : The word just before ? is captured.



##GREP - Count occurences of a char within a string
var="text,text,text,text"
GREP: reps=$(grep -o "," <<< "$var" | wc -l)
AWK Alternative: num=`echo $var |  awk -F"," '{print NF-1}'  #or {print NF?NF-1:0}
BASH Alternative: reps="${var//[^,]}" && echo "${#reps}"  #removes everything except comma


##GREP - Find non matching files instead of non  matching lines
$ grep -v ‘trivial information’  will not work because the rest of the lines in the file are match to this inverted search so the file.txt will end up in the result.
This job can be done using 
$ grep -L 'trivial information' *  (-L, --files-without-match)
With -L scanning will stop on the first match.

##GREP POSIXLY CORRECT OPTION
env POSIXLY_CORRECT=1 grep "hello" myfile -v ---> will raise an error for the -v flag (accepted to gnu grep)


##GREP INSTALL AN OLDER VERSION SIMULTANEOUSLY
You can apt download grep-version-you-like , you then extract grep from data.tar inside .deb, save it somewhere , rename it to grepold and copy this file to /bin
Same job for the manpage included in the .deb package. Just be sure to rename also the man page from grep.1.gz to grepold.1.gz (same name as renamed grep)

##GREP EXCLUDING COMMENTS
When you want to grep a conf or log file , it is usefull to exclude comments.
.I grep '^[^#]' /etc/squid/squid.conf
First '^' captures beginning of line. The synthax [^#] excludes #. All together '^[^#]' = grep the lines that starting (^) is NOT a # ([^#]).

Sometimes in big conf files you might want to know in which line of the file the parameter you want is located.
In this case for a file (i.e squid.conf) like this:
  # Recommended minimum configuration:
  #
  
  # Example rule allowing access from your local networks.
  # Adapt to list your (internal) IP networks from where browsing
  # should be allowed
  acl localnet src 0.0.0.1-0.255.255.255	# RFC 1122 "this" network (LAN)
  acl localnet src 10.0.0.0/8		# RFC 1918 local private network (LAN)
  acl localnet src 100.64.0.0/10		# RFC 6598 shared address space (CGN)

You want to know the line numbers using 'cat -n /etc/squid/squid.conf':
  1182	# Recommended minimum configuration:
  1183	#
  1184	
  1185	# Example rule allowing access from your local networks.
  1186	# Adapt to list your (internal) IP networks from where browsing
  1187	# should be allowed
  1188	acl localnet src 0.0.0.1-0.255.255.255	# RFC 1122 "this" network (LAN)
  1189	acl localnet src 10.0.0.0/8		# RFC 1918 local private network (LAN)
  1190	acl localnet src 100.64.0.0/10		# RFC 6598 shared address space (CGN)

You want to grep all the non-comment lines, preserving the line numbering of the inital file.
This can be done with a grep like this:
.I cat -n /etc/squid/squid.conf |grep -v '^\s*[0-9]*\s*[#]\|^\s*[0-9]*\s*$'
-v                 : return the non-matching lines
^\s*[0-9]*\s*[#]   : pattern 1 = Starting with space (\s) zero or more (*) following number ([0-9]) zero or more (*) following zero or more space following a single #
\|                 : OR
^\s*[0-9]*\s*$     : pattern 2 = starting with zero or more space, following zero or more numbers following zero or more space and then line end ($) = skip empty lines like 1184 above

Result: 
  <lines 1182-1187 are skipped>
  1188	acl localnet src 0.0.0.1-0.255.255.255	# RFC 1122 "this" network (LAN)
  1189	acl localnet src 10.0.0.0/8		# RFC 1918 local private network (LAN)
  1190	acl localnet src 100.64.0.0/10		# RFC 6598 shared address space (CGN)
  <.... more lines following bellow....>


#-----------------------------------------------------------------------------------------------------------------------

UTILS:CUT
https://www.gnu.org/software/coreutils/manual/html_node/cut-invocation.html#cut-invocation

cut can accept delimiter with -d'' and can return a range of fields (i.e -f1 , -f1,3 , -f1-3)
To assign a delimiter of \n,\t you have to use -d$'\n' (similar to IFS)

CUT can act directly on each line of file. You don't need while & read line loop.

Instead of -f option you can use cut to isolate part of text based on chars with -c option:
cut -c9-10 file ==> gets characters from 9 to 10. similary you can get c1-5 to get only the 5 first chars of EACH file line.
Also see this:  cut -c1,9-10 a.txt ==> gets 1st char and then gets chars 9-10

##INSERT DASH IN STRING
 String: #  1  2016-05-31-1003-57S._BKSR_003_CM6
 $ cut --output-delimiter='-' -c7-19,20-21 file.txt
 Output : 2016-05-31-10-03
 alternatives:
 $ awk '{print substr($3,0,13)"-"substr($3,14,2)}' file.txt
 $ while IFS= read -r line;do line="${line:6:13}-${line:14:2}";echo $line;done<file.txt
 $ sed 's/..$/-\0/g' <(cut -d- -f1-4 <(cut -d" " -f5- file.txt)) #use >newfile at the end to send the results to a new file

#-----------------------------------------------------------------------------------------------------------------------
UTILS:DIFF
## COMPARING FILES AND VARIABLES:
diff can compare two files line by line.
You can also trick use diff like this to compare two variables line by line : diff <(echo "$a") <(echo "$b") or diff <(cat <<<"$a") <(cat <<<"$b")

##COMPARE GREP RESULT IN A NICE VISUAL WAY:
diff -u  <(cat a.txt) <(grep "tar*" a.txt) #or -y

##REMOVE THE < char from output and keep only the differet items:
diff --changed-group-format='%<' --unchanged-group-format='' c.txt cc.txt
i.e c.txt 
1
2
3
cc.txt
1
2

##USING DIFF WITH PROCESS SUBSTITUTION 
diff -y <(man grep) <(man agrep) #compares man page of grep to manpage of agrep using -y = side by side
PS: normal usage of diff is diff -y file1 file2.

## DIFF TRICKS:
If you are in doubt about the results of a command like an extra grep you can compare results of previous command with new command like this:
diff -w -y <(apt search manpages |grep "/" |cut -d"/" -f1 |grep -E '^[a-zA-Z0-9]') <(apt search manpages |grep "/" |cut -d"/" -f1)
Differences will be noted with > symbol and then you can manually verify that the results of the new command (extra grep) is as expected.
Usefull when you want to verify the performance in commands that produce large output.

------------------------------------------------------------------------------------------------------------------------
UTILS:HEAD-TAIL
head -n1 : Gets the header - 1st line
tail -n+2 : Gets the second line up to EOF of a file - excludes header
Trick to get only one line from file using head and tail
Usage: bash viewline myfile 4
head -n $2 "$1" | tail -n 1

#-----------------------------------------------------------------------------------------------------------------------
UTILS:JOIN
Joins two files based on certain criteria.
join -a1 -o 1.2     - /dev/null # print the second field
join -a1 -o 1.2,1.1 - /dev/null # reorder the first two fields
See man join and also info join for better explanation

##INTERESTING OPTIONS OF JOIN: 
-a1 and/or -a2 : print non matched lines of file 1 and/or 2
-e EMPTY: replace missing lines EMPTY
-t char: Use char as delimiter
-1.2 : Join on field 2 of file 1
-2.4 : Join on field 4 of file 2
--nocheck_order : Don't complain about unsorted input files
--header : Treat 1st line as header
Tip: Combining join with LC_ALL=C in front, speeds up almost 40%.

##JOIN TWO FILES BASED ON COMMON FIELDS:
http://unix.stackexchange.com/questions/342814/combine-two-csv-file-based-on-condition#342839
join -o 0,1.2,1.3,2.3 <(sort A.csv) <(sort B.csv)
-o: Obey Format - specify a particular format. 
-o 0 : Stands for the merged /common field and is different than 1.1 or 2.1 who stand for file 1 field 1 and file 2 field 2.
If file2 has a line that is not present on file 1, then using -o 1.1 will print an empty space in that field.

##ANOTHER JOIN EXAMPLE: 
Join file b.txt and bb.txt. Preserve the contents of file b.txt and insert new contents from file bb.txt
If file bb.txt has similar parameters with different values, preserve the parameters of the original file b.txt - do not update

$ cat b.txt
parameterA=0
parameterB=1
parameterC=0

$ cat bb.txt
parameterA=0
parameterB=0
parameterC=0
parameterD=0

$ join -a1 -a2 -t= b.txt bb.txt |cut -d= -f1-2
parameterA=0
parameterB=1
parameterC=0
parameterD=0

##MORE JOIN EXAMPLES
File1            |File2
-----------------|------------
Category ID      |Purchase ID
C1  A1           |O1  A1

Resulting File3
O1 A1 C1

join -j 2 -o 2.1 2.2 1.1 File1 File2
Join on field 2 of both files (alternatively you can use -1.2 -2.2)
-o controls the output 

##JOIN CSV FILES (combine)
http://unix.stackexchange.com/questions/345051/concatenate-csv-with-some-shared-columns
$ join --nocheck-order -eNaN -13 -22 -t$'\t' -o 1.1 1.2 1.3 1.4 1.5 2.3 2.4 b.txt c.txt

Output:                     
A   B   C   D   E   F   G   
1   2   3   4   5   6   7   
NaN 1   2   NaN 1   2   1

#-----------------------------------------------------------------------------------------------------------------------
UTILS:PASTE : Merge lines of files
https://www.gnu.org/software/coreutils/manual/html_node/paste-invocation.html#paste-invocation
num2=file including 1,2 
let3=file including a,b,c
$ paste num2 let3
1       a
2       b
        c
$ paste -s num2 let3
1       2
a       b       c
$ paste num2 let3 num2 #reusing num2 file
1       a      1
2       b      2
        c
.I Print lines from two files (alternating):
$ cat file1
Aaaaaaa1
Aaaaaaa2

$ cat file2
Bbbbbbb1
Bbbbbbb2

$ paste -d $'\n' file1 file2 #or just -d '\n'. You can create an extra line using paste -d '\n' file1 file2 /dev/null since /dev/null counts as file
Aaaaaaa1
Bbbbbbb1
Aaaaaaa2
Bbbbbbb2

Bash tricky alternative:
while IFS= read -r line1 && IFS= read -ru3 line2; do
    echo "$line1"
    echo "$line2"
done < file1 3< file2

Also see this example: http://unix.stackexchange.com/questions/340691/stacked-records-to-columns/340692?noredirect=1#comment602328_340692
$ paste -d"," <(grep -E '[0-9]' c2.txt) <(grep -E '[a-z]' c2.txt)
Mind the process substitution of the same file. Remember that <(...) creates a temp fd descriptor which acts as a file argument in apps requesting files, like paste.

.I Tricky usage to join /reorganize lines of the same file
Considering a file with 10 lines , each line containing numbers like 1,2,3...10 (or seq 10)
Now we want to achieve this output:
1 2
3 4 5
6 7 
8 9 10

Means: join first two lines, then join next three lines, then repeat --> join two lines , join three lines and repeat up to EOF

One approach is an awk like this: awk '{printf("%s",$0 (NR%5==0?ORS:":"))}' file1 |awk -F':' '{print $1,$2;print $3,$4,$5}'
The initial file is grouped by 5 lines (separated by : ) and then we split it by 2 and by 3.

This can be done MORE easily with paste like this:
$ cat file1 |paste -s -d $' \n  \n'
-s = serialize
-d = delimiters
It is still not clear why and how it works, but it works.
It seems that each space before \n at delimiters correspond to the next line

Try to change the spaces:
$ seq 10 |paste -s -d $' \n   \n' #one more space added before last \n
1 2
3 4 5 6
7 8
9 10

Or even
$ seq 10 |paste -s -d $'  \n\n'
1 2 3
4
5 6 7
8
9 10

Similarily 
paste -s -d $' \n \n' will join lines by two ( like awk '{printf $0 (NR%2==0?ORS:OFS)}' )
PS: Classic paste alternative:seq 10 |paste -d ' ' - - #mind the two dashes = read stdin twice!

paste -s -d $'  \n  \n' will join lines by three ( equivalent to awk '{printf $0 (NR%3==0?ORS:OFS)}'
PS1: Classic paste alternative: seq 10 |paste -d ' ' - - -  #read stdin three times!
PS2: seq 10 |paste -d '%^' - - -   #Join 3 lines of the same file (seq 10 here) using delimiters = 1%2^3 etc

PS: Don't get confused by seq. Paste will work the same on any lines coming from any file

#-----------------------------------------------------------------------------------------------------------------------
UTILS:COLUMN
Print anything nicely with column program
Example : 'mount |column -t'. # -t stands for table . This does Auto cols detection & separation according to whitespace.
If columns are separated by delimiter, define this delimited by using '-s' option.
For files you can directly run '$column -t file.txt'

#-----------------------------------------------------------------------------------------------------------------------
UTILS:BC Calculator
a="$(<a.txt)" #supposing file "a" exists and has a number inside
b="$(<b.txt)" #similary
bc <<<"$a + $b"
c="$( bc <<<"$a + $b" )"

If the <<< syntax feels weird (it's called a "here-string" and is an extension to the POSIX shell syntax supported 
by bash and a few other shells), you may instead use printf to send the addition to bc:

printf '%s + %s\n' "$a" "$b" | bc
c="$( printf '%s + %s\n' "$a" "$b" | bc )"

##BC AND SCALE
scale can be used to adjust the number of decimal digits, but is not making any math rounding (printf does this job instead).
Moreover , in order scale to be "activated" bc expects to receive a division. scale is ignored in addition / subtraction

$ a="17.928671"; a=$(bc -l <<<"scale=3; $a");echo "$a"     ---> 17.928671  #scale ignored
$ a="17.928671"; a=$(bc <<<"$a/1");echo "$a"               ---> 17         #using bc without -l decimals are ignored
$ a="17.928671"; a=$(bc -l <<<"$a/1");echo "$a"            ---> 17.92867100000000000000  #scale active - max dec digits
$ a="17.928671"; a=$(bc -l <<<"scale=3; $a/1");echo "$a"   ---> 17.928                   #scale in effect
$ a="17.928671"; a=$(printf '%.3f\n' "$a");echo "$a"       ---> 17.929                   #rounding in effect
$ read a;printf '%.3f\n' $(bc -l <<<"$a")                  ---> bc will do the maths and printf will print them rounded. $a can be any expression

##TRICKY BC + PRINTF usage to sum up ascii values:
while read -rn1 char;do sumA+=$(printf '%d+' "'$char'");done <<<"1.Nf3 c5 2.e4 Nc6"
echo "$sumA"              ---->> 49+46+78+102+51+39+99+53+39+50+46+101+52+39+78+99+54+39+ #mind the trailing +
$ bc <<<"${sumA:0:-1}"    ---->> 1114
#-----------------------------------------------------------------------------------------------------------------------
UTILS: CAT AND TAC
Source Code of CAT:
http://git.savannah.gnu.org/gitweb/?p=coreutils.git;a=blob;f=src/cat.c;h=001408576c4c17a156c1e8761ed2d9c96aa3d0cf;hb=refs/heads/master
CAT help and man page are quite good. 
TAC is the opposite of CAT; Prints lines of file upside down (start from last).
cat -A or cat -vet displays non printable chars. Can be done better with |od -t x1c

#-----------------------------------------------------------------------------------------------------------------------
UTILS:LN - Create links.
Combine -s to create symbolic links; otherwise will create hardlinks.
Hardlinks remain when the original file is removed. Symlinks fail.
#-----------------------------------------------------------------------------------------------------------------------
UTILS:NL - Number Lines / Line numbering
Can be used / pipe / file to add numbers in file lines (similar to cat -n but MUCH more advanced).
Has a lot of options like starting number, number step, number acc to regex, etc
Simpliest usage : cat file |nl - default usage is equivalent to cat -b = number non empty lines only.
nl -bp"^$" c.txt --> apply numbering only on empty lines (start and end together)

#-----------------------------------------------------------------------------------------------------------------------
UTILS:TR
Replace new lines with null: 
 tr '\n' '\0' <in >out 
tr '\\n' '\\0' <in >out 
.ft B tr '\n' '\0' <in >out 

Mind the [=C=] synthax. Treats variations of the letter given as same letter . For example [=e=] will treat all 'e' (with tones, etc) as plain e
------------------------------------------------------------------------------------------------------------------------

UTILS:SORT 
http://www.skorks.com/2010/05/sort-files-like-a-master-with-the-linux-sort-command-bash/
Mind the options -u and -k for defininig the sort field (i.e -k2) and -t for setting fields delimiter (i.e -t"|" or -t:, etc)
-k lets you defind the sort key. You can have many -k entries.

Moreover with -k you can define except from the column (-k1) also the letters range to make the sort (i.e -k1,5 = 1st Col, chars 1 to 5)

More about -k : 
Syntax of -k is -k pos1,pos2 : from position1 to position2. If position 2 is ommited then is up to end of line.
Another syntax is k2.4,2.5   : The use of dot defines in which char of field 2 the key starts (here 4th char).
So the dot denotes a fixed point for key, while the comma denotes a range (from pos1 up to pos2)
 
As a result -k2.4,2.5 defines a key starting on field2-char4 up to key2 char5. If you ommit 2.5 , end of line will be used as ending point.

Defining a key like -t '.' -k1.1,1.0 matches the first field only , dot separated. Position 1.0 refers to the end of first field.

You can visually inspect the keys used by sort by using --debug . This will visualize the keys used:
$ find man* |LC_ALL=C sort --debug -t '|' -k1.3 #starting point is char3. Ending point missing = End of line.
sort: using simple byte comparison
mang
  __
____
manon
  ___

$ find man* |LC_ALL=C sort --debug -t '|' -k1.1,1.2 #first two chars
sort: using simple byte comparison
mang
__
____
manon
__
_____


Tip: To be sure that your -k selection works ok , you can apply for testing i.e -k3r (reverse). This means sort by 3rd column in reverse order.

Example:
root@debi64:/home/gv/Desktop# sort -k1,5 a.txt b.txt
crwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyzhrt/rth
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyzhrt/rth
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz/rhr/rthrh
-rw-rwxr--+  3 user1 hive       1462 2017-01-31 16:55 /user/anc/xyz/rhrhheh

root@debi64:/home/gv/Desktop# sort -k1,5 -k8r a.txt b.txt
crwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz/rhr/rthrh
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyzhrt/rth
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyzhrt/rth
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc
-rw-rwxr--+  3 user1 hive       1462 2017-01-31 16:55 /user/anc/xyz/rhrhheh


In the second example both files are sorted with key 1 to 5 and then are sorted with key 8 reversed.
Offcourse the results of second key are not capable to change the results of first key.
Is a nested /sub sort procedure to be used instead of pipe (sort -k1,5 |sort -k8)

root@debi64:/home/gv/Desktop# sort -k8 a.txt b.txt
drwxrwxr-x+  - user1 aive          0 2017-01-31 16:55 /user/abc
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc
root@debi64:/home/gv/Desktop# sort -k8 -k1r a.txt b.txt
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc
drwxrwxr-x+  - user1 aive          0 2017-01-31 16:55 /user/abc

If you need to extract duplicates based on specific columns ignoring data in the middle , uniq -d will not work.
# sort -k8 -k1r a.txt b.txt |uniq -d
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyzhrt/rth

You can then call awk to print the columns you need ($1 and $8) and then cut -d will work on output of awk.

##SORT -u option (unique)
sort -u a.txt b.txt == cat a.txt b.txt |sort |uniq
sort -u will exclude the duplicate lines, operation similar to classic uniq but with more criteria when used with -k

root@debi64:/home/gv/Desktop# sort -u a.txt b.txt #default sorting = based on k1 - c letter on first field goes on top
crwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz
drwxrwxr-x+  - user1 aive          0 2017-01-31 16:55 /user/abc
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc

root@debi64:/home/gv/Desktop# sort -u -k8 -k1 a.txt b.txt
drwxrwxr-x+  - user1 aive          0 2017-01-31 16:55 /user/abc
drwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/abc
crwxrwxr-x+  - user1 hive          0 2017-01-31 16:55 /user/anc/xyz
First sorted with k8 then with k1. abc folders go on top

##SORT EXCLUDING HEADER ROW
This is a common problem, since sort does not have a built switch to exlude header row.
Workarounds:
head -n1 file && sort <(tail -n+2 file) or head -n1 && tail -n+2 file |sort
{IFS= read -r header;echo "$header";sort} < file.csv
command | (read -r; printf "%s\n" "$REPLY"; sort)
awk 'NR == 1; NR > 1 {print $0 | "sort -n"}'
command | head -n 2; command | tail -n +3 | sort #command refers to your command (i.e cat , etc) not to the command utility
ps -ef | { head -1 ; sort ; }
function body { IFS= read -r header;printf '%s\n' "$header";"$@";};ps -o pid,comm | body sort -k2 #or |body grep pattern or |body whatever command you need to apply in the body 

------------------------------------------------------------------------------------------------------------------------
UTILS:DATE
##CONVERT DATE TO AN INTEGER
$ date +%Y%m%d%H%M%S   #Y=Year, m=month, d=day , H=Hour, M=minute,S=second
20180312001629 #this is an integer representing the current time
Such integers can be compared by bash using -lt -gt -eq etc

##CONVERT DATE TO EPOCH. 
date +%s  #prints current date in epoch seconds
date +%s --date "2018-03-12 23:50:00" # convert to epoch the specified date (if --date or -d is missing current date = now is used)
Epoch seconds can also be compared by bash as integers

##CONVERT EPOCH TO DATE 
Assuming that you have the string 1267619929 that represents timestamp/epoch date 
$ date -d @1267619929 +"%Y-%m-%d %H:%M:%S"   ---> 2010-03-03 14:38:49

PS: Some epoch times include milliseconds. In this case you need to divide the given epoch by 1000.

The last argument +"...." defines the output date format. 
By removing it you can get the std date output format:
$ date -d @1267619929   ---> Wed Mar  3 14:38:49 EET 2010

.I Using printf
Since Bash 4.2 you can use 
$ printf '%(datefmt)T\n' epoch
For datefmt you need a string accepted by strftime(3) - see man 3 strftime

$ printf '%(%c)T\n' 1267619929   --- > Wed 03 Mar 2010 01:38:49 PM CET
Here format %c is:
%c The preferred date and time representation for the current locale.

To make this work with a file in which epoch dates are stored:
$ printf '%(%F %T)T\n' $(cat file10)  #mind the on-purpose absence of double quotes - %F stands for Y-M-D and %T for H:M:S 
49990-01-04 04:47:16
49990-01-04 06:26:02
49990-01-04 11:06:03

To remove milliseconds , using printf and bc
printf '%(%F %T)T\n' $(printf '%s/1000\n' $(<file10) |bc)
2018-01-08 00:45:17
2018-01-08 00:45:23
2018-01-08 00:45:39


.I Using awk
echo 1267619929 |awk '{ $1 = strftime("%Y-%m-%d %H:%M:%S", $1) }1'

##DELETE LINES FROM LOG FILE OLDER THAN 30 days 
For a file with lines like 
2017/04/04 15:53:22 [11487] building file list)

You can exclude old logs using :
grep -v "$(date '+%Y/%m/%d' -d '30 days ago')*" logfile

##START/STOP A SCRIPT AT A TIME WINDOW 
This is a sample loop from now up to a specific time point:

stop=$(date +%Y%m%d%H%M%S --date "2018-03-12 00:20:55")   #converts given date (using the --date flag) to a kind of integer format.
while [[ $(date +%Y%m%d%H%M%S) -le $stop ]];do            #comparing current date & time with stop date & time
echo "date now is $(date)";
sleep 1;      #sleep 1 second
done

date now is Mon Mar 12 00:20:51 EET 2018
date now is Mon Mar 12 00:20:52 EET 2018
date now is Mon Mar 12 00:20:53 EET 2018
date now is Mon Mar 12 00:20:54 EET 2018
date now is Mon Mar 12 00:20:55 EET 2018


This is a similar script to start/stop at a specific time, but it is a bit "resources hungry" since it keeps comparing current time to start time:

date;             #just print the current date & time
compl=false;      #completed = false
start=$(date +%Y%m%d%H%M%S --date "2018-03-12 01:45:50");
stop=$(date +%Y%m%d%H%M%S --date "2018-03-12 01:45:55");
while true;do 
 while [[ $(date +%Y%m%d%H%M%S) -ge $start ]] && [[ $(date +%Y%m%d%H%M%S) -le $stop ]];do 
  echo "date now is $(date)";
  sleep 1;
  compl=true;
 done;
 ($compl) && break;   #if run then exit
done

Mon Mar 12 01:45:37 EET 2018
date now is Mon Mar 12 01:45:50 EET 2018
date now is Mon Mar 12 01:45:51 EET 2018
date now is Mon Mar 12 01:45:52 EET 2018
date now is Mon Mar 12 01:45:53 EET 2018
date now is Mon Mar 12 01:45:54 EET 2018
date now is Mon Mar 12 01:45:55 EET 2018


To make a loop with time you need to format date/time in such a way that can be comparable. The most easy trick is to transform date to something that will look like an integer and you then use lt,le,eq,gt,ge operators of bash.

Consider this :

$ date
Mon Mar 12 00:16:29 EET 2018 #this format/data type is not comparable by bash
$ date +%Y%m%d%H%M%S
20180312001629 #this is an integer representing the current time
This is a sample loop from now up to a specific time point:

stop=$(date +%Y%m%d%H%M%S --date "2018-03-12 00:20:55")
while [[ $(date +%Y%m%d%H%M%S) -le $stop ]];do #comparing current date & time with stop date & time
echo "date now is $(date)";
sleep 1;      #sleep 1 second
done

date now is Mon Mar 12 00:20:51 EET 2018
date now is Mon Mar 12 00:20:52 EET 2018
date now is Mon Mar 12 00:20:53 EET 2018
date now is Mon Mar 12 00:20:54 EET 2018
date now is Mon Mar 12 00:20:55 EET 2018
The trick here is that the command

stop=$(date +%Y%m%d%H%M%S --date "2018-03-12 00:20:55")
converts given date (using the --date flag) to a kind of integer format.

Then the while loop keeps comparing current date in the same integer format with the stop date.

This is a similar script to start/stop at a specific time, but it is a bit "resources hungry" since it keeps comparing current time to start time:

date;             #just print the current date & time
compl=false;
start=$(date +%Y%m%d%H%M%S --date "2018-03-12 01:45:50");
stop=$(date +%Y%m%d%H%M%S --date "2018-03-12 01:45:55");
while true;do 
 while [[ $(date +%Y%m%d%H%M%S) -ge $start ]] && [[ $(date +%Y%m%d%H%M%S) -le $stop ]];do 
  echo "date now is $(date)";
  sleep 1;
  compl=true;
 done;
 ($compl) && break;
done

Mon Mar 12 01:45:37 EET 2018
date now is Mon Mar 12 01:45:50 EET 2018
date now is Mon Mar 12 01:45:51 EET 2018
date now is Mon Mar 12 01:45:52 EET 2018
date now is Mon Mar 12 01:45:53 EET 2018
date now is Mon Mar 12 01:45:54 EET 2018
date now is Mon Mar 12 01:45:55 EET 2018


A very light alternative to start/stop a script at specific time would be to use epoch date / epoch seconds.

date                         #just print the current date & time
start="2018-03-12 02:17:52"
stop="2018-03-12 02:17:57"
timerequired=$(( $(date +%s --date "$start") - $(date +%s) ))
sleep $(($timerequired))     #sleep till the starting time 
while [[ $(date +%s) -le $(date +%s --date "$stop") ]];do 
  echo "date now is $(date)";
  sleep 1;
done

Mon Mar 12 02:17:39 EET 2018
date now is Mon Mar 12 02:17:52 EET 2018
date now is Mon Mar 12 02:17:53 EET 2018
date now is Mon Mar 12 02:17:54 EET 2018
date now is Mon Mar 12 02:17:55 EET 2018
date now is Mon Mar 12 02:17:56 EET 2018
date now is Mon Mar 12 02:17:57 EET 2018

------------------------------------------------------------------------------------------------------------------------
UTILS:GIT
https://git-scm.com/book/tr/v2/Git-Basics-Viewing-the-Commit-History
##BASIC COMMANDS
git add .
git commit -m "message"
git push

git pull to retrieve new files from git

##GIT HISTORY
git log : all the commits will be shown. Most recent goes on top.
git log -p -2 : gets only the last 2 commits
git log --stat : statistics about commits, like file changed . Also can be combined with --name-only.

git diff CommitIdNew-CommitIdOld like git diff 24226b9..3acf35c
Commit ids are advised in both git pull and git send
In git send:
   3acf35c..0774f59  master -> master
in git pull:
There is a relevant reference similar to git send.

##GIT SHOW FILES IN COMMIT
git show : see the last commit in details
git show --name-only : lists only file names changed
git show commitid :  Details about a particular commit id. Can be combined with --name-only. Commit id can be retrieved by git log

##GIT STORE PASSWORD
https://git-scm.com/docs/git-credential-store
git config credential.helper store
On the next push , your given user name and password will be stored.
Can be combined with options for expire, etc

------------------------------------------------------------------------------------------------------------------------
UTILS:TIME & STRACE
You can monitor performance in bash using the time or the strace utils.
time grep pattern file will  #report you details about the time required to execute command (grep)
strace -cf grep pattern file #will also report performance in a much more analytical way, displaying also all the processes to complete the command.

------------------------------------------------------------------------------------------------------------------------
UTILS:APT - APTITUDE etc
apt list pkg
apt list 'pkg*' # quote it to avoid bash globbing for * unless set -f is in action (globbing disable)
apt install pkg
apt purge pkg
apt install -t release pkg #install pkg and dependencies using specified release
apt install pkg/release    #install pkg but not dependencies using specified release. Dependencies will be used by current release.

apt show pkg  # Show details of pkg
apt search keyword  #Search all pkgs in all repos for the keyword/description given

apt-file search showmount   or /bin/showmount #advises which package you need to install in order to get showmount
OR JUST 
apt search showmount --> nfs-common  #or apt-cache search showmount

apt-file list pkg       --> List the contents of pkg

apt --print-uris install pkg   # Returns the names of the .deb packages that will be installed in case of apt install. Works also with apt-get
apt --print-uris download pkg  # Returns the deb file that apt download pkg would download:
apt --print-uris download nfs-common  ---> 'http://ftp.gr.debian.org/debian/pool/main/n/nfs-utils/nfs-common_1.3.4-2.1_amd64.deb' nfs-common_1%3a1.3.4-2.1_amd64.deb 230730 SHA256:8fedb6f5d28d521ca6b1623610255c7edf26c011b3c45e07e19e4378902bfab4

apt-mark hold kodi kodi-bin kodi-data kodi-repository-kodi  #hold those packages to avoid updating by apt-get update
apt-mark unhold pkg # unholds a package. Can be used to unhold all packages like apt-mark unhold $(apt list --installed 2>/dev/null |cut -f1 -d'/')
apt-mark manual pkg  #sets the manual installed flag for a pkg

apt-get changelog thunar/unstable  #downloads and displays changelog of pkg. 
Get:1 http://metadata.ftp-master.debian.org thunar 1.8.1-1 Changelog [37.3 kB]
Fetched 37.3 kB in 0s (121 kB/s)

zless /usr/share/doc/thunar/changelog.Debian.gz    #Dsiplays changelog of installed pkg

apt-file search file     #returns all apt pkgs containing the file
apt-file list pkgname    #list files installed by pkg. Similar to dpkg -L for not installed pkgs.

.B Ignoring Dependencies that holds/stops the whole apt-get upgrade 
Open the file /var/lib/dpkg/status, find the pkg that creates the conflict and remove the problematic dependency 
from the Depends: section 

.B APTITUDE
Aptitude seems to have better upgrade handling & capabilities.

aptitude autoclean #Erase old downloaded package files - Deleted 20GB (!) from my disk of old installation files.

Other common commands:
aptitude install/remove/purge
aptitude hold/unhold/markauto/unmarkauto
aptitude forbid-version
aptitude update/safe-upgrade/full-upgrade
aptitude build-dep
aptitude forget-new
aptitude search/show/showsrc/versions
aptitude clean       #Erase downloaded package files.
aptitude autoclean   #Erase old downloaded package files.
aptitude changelog
aptitude download
aptitude source
aptitude reinstall
aptitude why/why-not

Switches:
aptitude --help
-s              Simulate - dry run
-d              Only download packages, do not install or remove anything.
-P              Always prompt for confirmation of actions.
-y              Assume that the answer to simple yes/no questions is 'yes'.
-F format       Specify a format for displaying search results; see the manual.
-O order        Specify how search results should be sorted; see the manual.
-w width        Specify the display width for formatting search results.
-f              Aggressively try to fix broken packages.
-V              Show which versions of packages are to be installed.
-D              Show the dependencies of automatically changed packages.
-Z              Show the change in installed size of each package.
-v              Display extra information. (may be supplied multiple times).
-t [release]    Set the release from which packages should be installed.
-q              In command-line mode, suppress the incremental progress indicators.
-o key=val      Directly set the configuration option named 'key'.
--with(out)-recommends     Specify whether or not to treat recommends as strong dependencies.
-S fname        Read the aptitude extended status info from fname.


------------------------------------------------------------------------------------------------------------------------
UTILS:SIZE OF FILES - DISK USAGE (DU,LS,etc)
du reports by default size of directories. Can be combined with -a to report also size of files (by default directories sizes is reported)
Also -d1 restricts max depth to 1. -b returns the real file size and -h returns size in human readable format. -s is for sumarize
Output of du is by default tab separated. If directory is ommited , current working directory is reported.
You can avoid -a and provide to du * or ./* to force report the files.
If you use -d1 you can force subdirs (of first level) with ./*/ (enabling bash options you can go deeper)

$ du -b -h -s /etc
5.0M    /etc

$ du -ab -h -d1 /etc
8.2K    /etc/ufw
42K /etc/gimp
12K /etc/sysstat
4.0K    /etc/foomatic
22K /etc/perl
14K /etc/dpkg
4.4K    /etc/ldap
40K /etc/mailcap
6.8K    /etc/UPower
81K /etc/dbus-1


$ find . -maxdepth 1 -printf %f-%s\\n  #Output in pure bytes - no human readable option available
bsd.txt-173
file4-3
shellcolors.sh-684

Tip1: For binary/compiled files check out size utility

Tip2: Get easily the size of any file in human readable format using ls -lh

------------------------------------------------------------------------------------------------------------------------
UTILS:XARGS
xargs can be used to separate arguments. default action is echo .
also can be used to transform output of previous commands to command line options for another command that does not accept stdin - can not pipe

Options:
-l = max lines. It's use it is depreacated and posix /bsd usage -L1 must be used. 
-t = verbose . Print each command before execution
-p = prompt for user confirmation before running each command. Requires -t.
-r = no run if empty args. Usefull in double greps
-d'\n' = args delimiter
-a = read arguments from file instead of stdin

Various usage examples:

tr '\n' '\0' < file | xargs -0 mkdir
xargs -d '\n' mkdir -p < file        #GNU Xargs with -d (delimiter) set to \n. Usefull if the file contains dirname with spaces.
grep -r 'someword' |xargs -r grep otherword   #chained greps - xargs -r filters out empty data (second grep does not called if empty result is passed by first grep)
find . -type f -name '*.txt' -print0 |xargs -0 somecommand_here
xargs -a list.txt -d'\n' rm    --> removes all the files in a list.txt file. Alternative : rm $(<list.txt)

echo -e "foo bar\ndoo dar" | xargs -n 2 mv  --> -n = max number of args per command. This results to mv foo bar and mv doo dar - tested and working ok
echo "mbar bar\nmbaz baz" | xargs mv  --> This is wrong usage. It is translated by xargs like mv mbar bar mbaz baz
echo "mbar bar\nmbaz baz" | xargs -l -t mv  -->  Not tested by me but by others. Results to mv mbar bar and mv mbaz baz

using xargs to operate over files is not suggested.
For example in above xargs mv, we need to provide the files in a special way (i.e quoted) to handle files with special chars 
like space in filename, single/double quotes, etc
echo "mbar bar\n'my foo' foo" | xargs -l -t mv  --> works ok. Without quoting around file "my foo" the mv breaks

------------------------------------------------------------------------------------------------------------------------
UTILS:SEQ
Produces a sequence. 

Classic use: 
$ seq 10 --> produces lines from 1 to 10. Can be used to quickly emulate lines of a file : seq 10 |awk ....

Tricky usage:
$ start=3; seq -s" : " -f "data%g" $start 5    ---> data3 : data4 : data5
-s" : " - item separator

------------------------------------------------------------------------------------------------------------------------
UTILS:TEXT TO ASCII :http://artii.herokuapp.com/
$ curl http://artii.herokuapp.com/make?text=Welcome++++Back++++George+\!+\!;echo
you can assign it in a variable using $( ), you can store in a file with redirection >, etc

------------------------------------------------------------------------------------------------------------------------
UTILS:TIMEOUT
$ timeout command
Start COMMAND, and kill it if still running after DURATION.
For example : timeout 2 yes
timeout --foreground 12s tail -f access.log

------------------------------------------------------------------------------------------------------------------------
UTILS:XDOTOOL
http://tuxradar.com/content/xdotool-script-your-mouse

Is actually an X utility in which you can script the mouse moves = programmatically emmit a click or make a mouse move
Consider that upper left corner is 0x0 and bottom right corner is 1366x768 (XxY as reported by xrandr - current / active setting)

Try those ones: 
# xdotool mousemove 1300 500 - mouse moves 1300 to the left and 500 down, 
# xdotool mousemove 0 0 click 1 (or click 3)

You can make automation scripts either on fixed windows using absolute coords, or in particular windows using relative coords.

More examples: 
$ xdotool search "Notes" windowactivate --sync type "hello George, how are you?"  #Assuming that a notes window is present
$ xdotool key ctrl+c
$ xdotool key F1

Open a new LibreOffice Draw document, select the line tool and run on terminal this one:
$ xdotool search "Untitled" windowactivate --sync mousemove --window %1 300 300  && sleep 0.5 && xdotool mousedown 1 && sleep 0.5 && xdotool mousemove_relative --sync 400 400 && sleep 0.5 && xdotool mouseup 1
You should see a straight line draw automatically 

------------------------------------------------------------------------------------------------------------------------
UTILS:SYSTEM INFO
id -u gv            #prints the id of user gv
w -hs               #prints logged in users (gv & root)
fgconsole           #prints tty number = 7. can be used in scripts like tty$(fgconsole)
HDMI_STATUS=$(cat /sys/class/drm/card0/*HDMI*/status)

.I UPOWER = Power Manager - freedesktop
upower -e : Display devices controlled by power manager
upower -d : Dump parameter of all objects
upower -i /org/freedesktop/UPower/devices/battery_BAT0 --> display parameters of battery 0 = first system battery. Combine with grep.
function power {
echo "AC Power" && upower -i "$(upower -e |grep 'line_power')" |grep -e 'native-path' -e 'online' |sed -r 's/^\s+//g'
echo && echo "Battery" && upower -i "$(upower -e |grep -e 'BAT')" |grep -e 'state' -e 'percentage' -e 'time to' -e 'native-path' |sed -r 's/^\s+//g'
}
PS: You can make use of upower in scripts to determine if PC runs on battery or on AC power.

PS: You can nativelly get the same info by cat on the files of directory 
Browsing '/sys/class/power_supply/' will drive you to BAT0 and AC0
/sys/class/power_supply/BAT0 ---> link to /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A08:00/PNP0C0A:03/power_supply/BAT0
/sys/class/power_supply/AC0  ---> link to /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A08:00/ACPI0003:00/power_supply/AC0

------------------------------------------------------------------------------------------------------------------------
UTILS:WGET & CURL
##WGET Switches
-nv                     : no verbose
--content-disposition   : some like http://www.enersys.com/WorkArea/DownloadAsset.aspx?id=301 will save the file with name id=301
                        : using --content-disposition the real file name will be used - usually hidden in the HEAD section of the webpage

##CURL Switches
-O          : Keep Remote Name
-L          : Follow Redirections
-J          : Get Remote Header Name
-s          : Silent
-o filename : output . Used very often like -o - to dump contents on the terminal and then to be piped

##Download Multiple Files by WebSite
for i in {300..500};do wget -nv --content-disposition http://www.enersys.com/WorkArea/DownloadAsset.aspx?id=$i;done
Will download all files from webpage with id=300 up to id=500

.I Alternativelly 
curl -OJL http://....
-O : Keep Remote Name , -L : Follow Redirections , -J : Get Remote Header Name

------------------------------------------------------------------------------------------------------------------------
UTILS:YOUTUBE-DL - MPV
https://github.com/rg3/youtube-dl

https://oload.win/stream/5KSeX_DV9Y4~1523564561~176.92.0.0~TRYa2RIQ

##Default Usage
$ youtube-dl https://www.youtube.com/watch?v=o0yimq6W5Y8
$ youtube-dl -v -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' https://openload.co/embed/5KSeX_DV9Y4/

By default , youtube-dl downloads video file and audio file separately in a two steps process and then it merges and synchronizes those two files.
Temp Files are deleted by default unless -k (keep) option is given.

##List Codecs
$ youtube-dl -F url #displays available video and audio formats (selectable by format code)

##Get only the video without audio
Can be done by specifying a particular video only format, like -f 134 (if 134 is a valid video only format for your video):
$ youtube-dl -f 134 http://youtubturl 

Mind that -f best will download both video and audio

##Get the video with audio
$ youtube-dl -f 134+251 url 
gets youtube video with video format 135 and audio format 125 and merges those two in a single file - local video
Mind that video format is given first and audio format is given second: -f XXX+YYY (XXX is video and YYY is audio codec)

If unsure which format codes to select use this global syntax:
$ youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' https://www.youtube.com/watch?v=FoTsbrPxP8I

You can also use just -f best which seems to download the best video + best audio at once.

##Extract Audio:
$ youtube-dl --extract-audio --audio-format mp3 https://www.youtube.com/watch?v=FoTsbrPxP8I  #extracts audio in mp3. Requires ffmpeg to be installed.

##Get real video urls :
$ youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' --get-url https://www.youtube.com/watch?v=FoTsbrPxP8I
https://r2---sn-jtu5bgxxjx-5uis.googlevideo.com/videoplayback?id=1684ec6eb3f13fc2&itag=135&source=youtube&requiressl=yes&ei=n3vJWY6QMpPdWM6yqeAE&ms=au&initcwndbps=558750&pl=16&mv=m&mm=31&mn=sn-jtu5bgxxjx-5uis&pcm2cms=yes&ratebypass=yes&mime=video/mp4&gir=yes&clen=22267226&lmt=1480146626325700&dur=189.760&mt=1506376513&key=dg_yt0&signature=7B349CE08E2AB0D2154B30B864EF9C9B96F60E4E.4DC031B2476260349DCE899E5794B469FA8CF95C&ip=176.92.92.88&ipbits=0&expire=1506398207&sparams=ip,ipbits,expire,id,itag,source,requiressl,ei,ms,initcwndbps,pl,mv,mm,mn,pcm2cms,ratebypass,mime,gir,clen,lmt,dur
https://r2---sn-jtu5bgxxjx-5uis.googlevideo.com/videoplayback?id=1684ec6eb3f13fc2&itag=140&source=youtube&requiressl=yes&ei=n3vJWY6QMpPdWM6yqeAE&ms=au&initcwndbps=558750&pl=16&mv=m&mm=31&mn=sn-jtu5bgxxjx-5uis&pcm2cms=yes&ratebypass=yes&mime=audio/mp4&gir=yes&clen=3015473&lmt=1480133239302273&dur=189.823&mt=1506376513&key=dg_yt0&signature=4D01849E5C21A0BB8D9189D949F7D4C2B50DA676.1A23DA1855CEA7D4EE7E0CC913C5ADAA9CBBC232&ip=176.92.92.88&ipbits=0&expire=1506398207&sparams=ip,ipbits,expire,id,itag,source,requiressl,ei,ms,initcwndbps,pl,mv,mm,mn,pcm2cms,ratebypass,mime,gir,clen,lmt,dur

First url is video only , second url is audio only. Both urls can be opened in browser and contain a download button.

##Download a portion (crop) of a video:
https://nicktux.com/2017/09/24/youtubedl-ffmpeg-download-specific-timing/

$ ffmpeg -ss 10 -i $(youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' --get-url https://www.youtube.com/watch?v=FoTsbrPxP8I) -t 10 -c:v copy -c:a copy testvid.mp4
-ss  : starting point
-i   : input file
-t   : duration before to close output
-c:v copy: just copy the existed video codec - no re-coding
-c:a copy: just copy present audio codec - no re-coding

This should work according to nicktux but is not working in my Debian.
youtube-dl --get-url returns two urls: one for video which is recognized and one for audio which is not recognized and ffmpeg fails.

##Simultaneously watch and save a movie by opencloud
https://unix.stackexchange.com/questions/279884/play-subtitles-automatically-with-mpv
https://superuser.com/questions/1136372/watch-movie-while-downloading-it

Requires mpv , youtube-dl and ffmpeg. mpv will automatically install the required tools ffmpeg & youtube-dl
OpenCloud usually provides an 'embed' option like this:
<iframe src="https://openload.co/embed/BmB-MDfowlc/" scrolling="no" frameborder="0" width="700" height="430" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>

If you curl https://openload.co/embed/BmB-MDfowlc/ |grep 'vtt' will return you the subtitles location.
$ curl -s https://openload.co/embed/BmB-MDfowlc/ |grep -m1 'vtt' |grep -o 'src=\".*vtt\"'
src="https://thumb.oloadcdn.net/subtitle/BmB-MDfowlc/ahwISdzLQBo.vtt"
or even 
$ curl -s https://openload.co/embed/BmB-MDfowlc/ |grep -m1 'vtt' |grep -Po 'src=\"\K.*vtt'
https://thumb.oloadcdn.net/subtitle/BmB-MDfowlc/ahwISdzLQBo.vtt

Caution: Sometimes the openload embed link is given in plain html and not in https. If curl doesnot return any result at all (zero bytes captured) replace http with https and tryagain.

You can then wget this vtt file: wget https://thumb.oloadcdn.net/subtitle/BmB-MDfowlc/ahwISdzLQBo.vtt

You can then use youtube-dl to get & play the video:
$ youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' https://openload.co/embed/BmB-MDfowlc/ -o- |tee test.mp4 |mpv --sub-file=ahwISdzLQBo.vtt -
-o- option in youtube-dl outputs the video file to '-' = screen/tty 
tee writes those tty data to file and re-prints them in tty
mpv player reads data from '-' = /dev/stdin=tty while loading the subs file previously got with wget

As of August 2018, has been proved that mpv can directly read the vtt file from remote source without previously wget-ting the file:
youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' "http://openload.co/embed/1AfWyTzfRcg/LwndrdrSVS1-1.avi" -o- |mpv --sub-file="https://thumb.oloadcdn.net/subtitle/1AfWyTzfRcg/sCt2OvM6F8Q.vtt" -

.I Tips & Bugs
0. https://9xbuddy.com/sites/openload 
Above website will give you subtitles vtt link and real video mp4 link suitable for downloading or curl or direct mpv playing

1. There is no direct way to force youtube-dl to automatically download subs from the 'embed' url- This command returns nothing:
$ youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' --list-subs 'https://openload.co/embed/BmB-MDfowlc/'
[Openload] BmB-MDfowlc: Downloading webpage
[Openload] BmB-MDfowlc: Executing JS on webpage
BmB-MDfowlc has no subtitles

2. You can get the direct video url like:
$ youtube-dl --get-url 'https://openload.co/embed/BmB-MDfowlc/'
https://openload.co/stream/BmB-MDfowlc~1514335530~176.92.0.0~t0DoWtve?mime=true
PS: No longer works in March 2018

If you open above link in your browser you are redirected to 
https://1fgm8jn.oloadcdn.net/dl/l/Q3HCbea0iBCYr8kz/BmB-MDfowlc/2839-BR720-SUBS-HACKSAW.mp4?mime=true
You can find a download icon there for direct download but without subtitles

3. You can also use wget to watch & save a movie:
$ wget http://cclicence.film/myfavourite.mp4 -O- | tee myfav.mp4 | mpv - #or |mpv --sub-file=file.srt -
wget can not 'extract' video urls so you need to provide the exact video url

4. In case of embeded openload videos in webpages like http://teniesonline.ucoz.com/load/2-1-0-1485 you can curl the webpage
and then grep for openload or embed:
curl http://teniesonline.ucoz.com/load/2-1-0-1485 |grep 'open'
<various lines but one is like that>
<option selected="selected" value="">Επιλέξτε Player για προβολή</option> <br /> <br /> <option value="https://openload.co/embed/KD9TigOuVZ0/">Openload.co</option> <br /> <br /> </select></div></center></nofollow> 

As already explained the embeded openload links contain both mp4 file and vtt. You can further curl this embed url and grp for subs / vtt

5. Openload hides real source behind jscript. So day by day openload improves js and youtube-dl fails to catch the stream url.

Workaround 1: 
Open the embed link in browser and look at source code. 
For embed url https://openload.co/embed/5KSeX_DV9Y4/ , browsing the source you will something like:
<video class="vjs-tech" id="olvideo_html5_api" crossorigin="anonymous" poster="https://thumb.oloadcdn.net/splash/5KSeX_DV9Y4/pUHDM0i7V74.jpg" src="/stream/5KSeX_DV9Y4~1523568076~176.92.0.0~0IUY-wyi?mime=true">

This code snippet will appear when the video is really playing in your screen.... (all the commercials are finished)

The url given above i src="/stream/..." is the real source. 
You can "copy link address" with right click: https://openload.co/stream/5KSeX_DV9Y4~1523568076~176.92.0.0~0IUY-wyi?mime=true #delete ?mime=true

Above link address works fine with youtube-dl so this command works fine:
$ youtube-dl -v -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' https://openload.co/stream/5KSeX_DV9Y4~1523568076~176.92.0.0~0IUY-wyi -o- |mpv -

In most cases mpv can work directly with above stream url:
$ mpv https://openload.co/stream/5KSeX_DV9Y4~1523568076~176.92.0.0~0IUY-wyi

Workaroud 2: 
Hit the 'download' button in browser/openload web page till browser starts to download the video.
Go to 'Show all downloads' and copy the download link that is in use by your web browser.
Use this link either directly to mpv or to youtube-dl |tee |mpv

------------------------------------------------------------------------------------------------------------------------
UTILS:SYSTEMD WIFI RESET AFTER SLEEP / HYBERNATE RESUME
.I Forcing a Reset (check alias wfr)
To force a wifi reset those works in Debian 9.0:
1. nmcli radio wifi off && sleep 10 && nmcli radio wifi on #nmcli = network-manager command line interface
2. systemctl restart network-manager

While both commands work, the first one seems to emulate the 'wifi off' laptop button , while the second one is purelly SW based restart

.I Reset by script
People claim that scripts located in bellow directories run on system resume:
1. Directory /usr/lib/pm-utils/sleep.d  --> Not working on Debian 9
2. Directory /lib/systemd/system-sleep/ - Explained here: https://wiki.archlinux.org/index.php/Power_management#Hooks_in_.2Fusr.2Flib.2Fsystemd.2Fsystem-sleep

First method does not work, but second method works fine. Better way to test script is with echo to a tmp log file i.e in Desktop 
Systemd transmits two arguments ($1/$2) in all the scripts present in above directory.
$1 gets value 'pre' or 'post' (prior sleep / after sleep)
$2 gets value like sleep, hybernate and hybrid-sleep

Typical script:

#!/bin/sh
case $1/$2 in
  pre/*)
    echo "Going to $2..."
    # Place your pre suspend commands here, or `exit 0` if no pre suspend action required
    ;;
  post/*)
    echo "Waking up from $2..."
    # Place your post suspend (resume) commands here, or `exit 0` if no post suspend action required
    ;;
esac

.I Reset Wifi by customized systemd service
https://askubuntu.com/questions/761180/wifi-doesnt-work-after-suspend-after-16-04-upgrade

1. Create a service : sudo nano /lib/systemd/system/wifi-resume.service
PS:The service is calling the program from /etc/init.d/network-manager

2. Write the service code:

#/lib/systemd/system/wifi-resume.service
#sudo systemctl enable wifi-resume.service
[Unit]
Description=Restart network-manager at resume
After=suspend.target
After=hibernate.target
After=hybrid-sleep.target 
#all this target files exist in /lib/systemd/system directory

[Service]
Type=oneshot
ExecStart=/bin/systemctl restart network-manager  #Command works fine even in my Debian 9

[Install]
WantedBy=suspend.target
WantedBy=hibernate.target
WantedBy=hybrid-sleep.target

3. Enable the service: sudo systemctl enable /lib/systemd/system/wifi-resume.service
This creates the symlinks into the indicated [Install] directories of /etc/systemd/system and activates the service

4. Check status with systemctl status wifi-resume.service

.I Verifying sleep/hybernate states
journalctl -b -u systemd-suspend


------------------------------------------------------------------------------------------------------------------------
UTILS:MOREUTILS

##Moreutils
This is a package with some usefull perl/c utils:

/usr/bin/chronic    ---> runs a command quietly unless it fails
/usr/bin/combine    ---> a perl utility to print lines from two files using and/or/xor . i.e print if lines are present in file1 and file2
/usr/bin/errno      ---> look up errno names and descriptions. Run with --list for a full errors list.
/usr/bin/ifdatap    ---> get network interface info without parsing ifconfig output
/usr/bin/ifne       ---> ifne runs the following command if and only if the standard input is not empty. There is also the opposite using -r (reverse) switch 
/usr/bin/isutf8     ---> check whether files are valid UTF-8
/usr/bin/lckdo      ---> run a program with a lock held
/usr/bin/mispipe    ---> pipe two commands, returning the exit status of the first
/usr/bin/parallel   ---> run programs in parallel
/usr/bin/pee        ---> Similar to tee but for pipes. Can drive two different commands, i.e cat file1 |pee 'awk "NR==5"' 'awk "NR==2"'
/usr/bin/sponge     ---> holds the data piped to sponge and prints those data when file is finished. Different to tee, which prints out whatever comes in
/usr/bin/ts         ---> time stamp input. Usefull in tail -f
/usr/bin/vidir      ---> edit (vi) a directory in editor. Delete a file from editor, and file will be deleted FOR REAL by the directory.
/usr/bin/vipe       ---> pipe editor. Command cat file1 |vipe |sed will open nano to make changes in a tmp file after cat and before to be piped to sed
/usr/bin/zrun       ---> run a program from a compressed archive. i.e zrun cat /usr/share/info/sed.info.gz

See the whole man pages without installing using $debcat moreutils --ind --readable

--------------------------------------------------------------------------------------------------------------------------
UTILS:DEVSCRIPTS
https://packages.debian.org/sid/devscripts
This is a package with some usefull perl/shell scripts. 

.B Scripts of some interest:

 - annotate-output: run a command and prepend time and stream (O for stdout,E for stderr)
 - build-rdeps: Searches for all packages that build-depend on a given package.
 - chdist: tool to easily play with several distributions. 
 - checkbashisms: check whether a /bin/sh script contains any common bash-specific constructs.
 - debc: List contents of current package.  Do this after a successful "debuild" to see if the package looks all right.
 - debchange (abbreviation dch): Modifies debian/changelog and manages version numbers for you.
 - debdiff: A program which examines two .deb files or two .changes files and reports on any difference found in their file lists.  
 - desktop2menu: given a freedesktop.org desktop file, generate a skeleton for a menu file. 
 - dscextract: extract a single file from a Debian source package. 
 - dscverify: check the signature and MD5 sums of a dsc file against the most current Debian keyring on your system. 
 - grep-excuses: grep britney's excuses to find out what is happening to your packages. 
 - list-unreleased: searches for packages marked UNRELEASED in their changelog.
 - manpage-alert: locate binaries without corresponding manpages. 
 - mass-bug: mass-file bug reports. 
 - mk-build-deps: Given a package name and/or control file, generate a binary package which may be installed to satisfy the build-dependencies of the given package. 
 - namecheck: Check project names are not already taken.
 - nmudiff: prepare a diff of this version (presumably an NMU against the previously released version (as per the changelog) and submit the diff to the BTS. 
 - origtargz: fetch the orig tarball of a Debian package from various sources, and unpack it.
 - plotchangelog: display information from a changelog graphically using gnuplot. 
 - rc-alert: list installed packages which have release-critical bugs.
 - rmadison: remotely query the Debian archive database about packages.
 - suspicious-source: output a list of files which are not common source files. 
 - tagpending: runs from a Debian source tree and tags bugs that are to be closed in the latest changelog as pending. 
 - uscan: Automatically scan for and download upstream updates.  
 - uupdate: Update the package with an archive or patches from an upstream author.  
 - what-patch: determine what patch system, if any, a source package is using.
 - whodepends: check which maintainers' packages depend on a package.
 - who-permits-upload: Retrieve information about Debian Maintainer access control lists. 
 - who-uploads: determine the most recent uploaders of a package to the Debian archive. 
 - wnpp-alert: list installed packages which are orphaned or up for adoption.
 - wnpp-check: check whether there is an open request for packaging or intention to package bug for a package. 
 - wrap-and-sort: wrap long lines and sort items in packaging files.
 
------------------------------------------------------------------------------------------------------------------------
UTILS:DPKG
dpkg-query -l pkg : advises if a programm is installed or not. Returns 0 if installed, 1 if not installed.
dpkg -s pkg       : same as above, providing much detailed info if installed (equivalent to apt show pkg
dpkg -L pkg       : Displays the files that pkg installed in your system, including dirs, /bin/files etc. Usefull if pkg name does not match executable name 
dpkg --info       : Examine a .deb file
dpkg --contents   : list the contents of a deb file
dpkg -i debfile   : installs the saved deb file. If installation breaks , you can use apt-get install -f and will correct dependencies errors
dpkg --purge pkg  : removes a pkg - like apt purge pkg
dpkg --print/remove/add-architecture : prints or removes or add an architecture like [amd64]
dpkg -S file      : searches for file installed. Similar to bash command -v file. Fails on pkgs.
dpkg --dry-run    : global switch that simulates the action choosen. No changes made to the system


.B Install the same software on a second Debian server
On the source machine:
dpkg --get-selections > installed-software.log

On the destination machine:
apt-get install dselect 
dpkg --set-selections < installed-software.log 
apt-get dselect-upgrade

------------------------------------------------------------------------------------------------------------------------
UTILS:GITHUB PROJECTS - CLI SERVICES COLLECTION - TIPS AND TRICKS
https://github.com/chubin/awesome-console-services

.I IP address
curl https://canihazip.com/s
curl ipinfo.io/ip
curl icanhazip.com
curl curlmyip.net
curl ipecho.net/plain
curl ifcfg.me
curl ifconfig.me
curl ip-addr.es
dig +short myip.opendns.com @resolver1.opendns.com

.I IP-based geolocation
curl ipinfo.io/8.8.8.8 or curl ipinfo.io/8.8.8.8/loc
curl freegeoip.net/csv/8.8.8.8 or freegeoip.net/xml/4.2.2.2 or freegeoip.net/json/github.com

.I Text Sharing (like pastebin)
ix.io
sprunge.us
ptpb.pw

.I URL shortener
curl -s http://tinyurl.com/api-create.php?url=http://www.google.com

.I File Transfer
curl --upload-file <file> transfer.sh/<filename>

.I Tools
curl qrenco.de/STRING or echo STRING | curl -F-=\<- qrenco.de — create QR-code for a string (chubin/qrenco.de)

.I Weather
https://github.com/chubin/wttr.in

curl wttr.in or curl wttr.in/Berlin - the right way to check the weather
curl wttr.in/'Νέα Ερυθραία'
finger oslo@graph.no

.I Exchange rates and financial information
curl rate.sx     #get cryptocurrencies exchange rates. Also curl rate.sx/btc or even /btc@100d
curl moneroj.org #get Monero exchange rate

.I Manuals, cheat sheets and FAQs
curl cheat.sh - UNIX/Linux commands cheat sheets using curl (chubin/cheat.sh)
Dictionaries and translators
curl 'dict://dict.org/d:command line'

.I Messages/texts/jokes/fortunes/names generators
git commit -m $(curl -sk https://whatthecommit.com/index.txt) — generate random commit message
curl -H 'Accept: text/plain' foaas.com/cool/:from — fuck off as a service
curl -s https://uinames.com/api/?region=france\&amount=25 | jq '.[] | .name +" " + .surname' — generate 25 random french names
curl https://icanhazdadjoke.com — random jokes

.I Chats, games and fun
nc towel.blinkenlights.nl 23 — watch StarWars in terminal
ssh chat.shazow.net — chat over SSH (shazow/ssh-chat)

.I Clients
At least on of the clients, that you need to access these services, is installed in almost every UNIX/Linux system.
curl/curl
httpie — modern command line HTTP client
wget
links   #check the -dump option
lynx    #check the -dump option

.I View an image from web without downloading
PS: You need an image viewer to be capable to read from stdin like ImageMagick or feh

curl -s https://www.ipchicken.com/images/main_03.gif |display   #ImageMagick
curl -s https://www.ipchicken.com/images/main_03.gif |display -resize 640x480 -  #ImageMagick. Don't forget the dash in the end, otherwise resize does not work
curl -s https://www.ipchicken.com/images/main_03.gif |feh -     #Feh

PS2: eog,eom and xfce viewere ristretto do not work with - or /dev/stdin (i.e eom - or eom /dev/stdin

.I Mount and ISO file
mount -o loop amazing.iso /mnt/disk
umount amazing.iso  (unmount)

.I  Record a terminal session with asciinema
asciinema rec file      #https://asciinema.org/docs/installation#installing-on-linux

.I Use avconv to convert .ape to .mp3
sudo apt install libav-tools
avconv -i 'Asia - Silent Nation.ape' -id3v2_version 3 -codec:a libmp3lame -b:a 320k 'Asia-Silent.Nation.mp3'

------------------------------------------------------------------------------------------------------------------------
UTILS:DD COPY
.B MAKE A BOOTABLE CD USING DD
dd bs=4M if=kali-linux-xfce-2017.3-amd64.iso of=/dev/sdb conv=fdatasync   #tested and worked fine

.I not tested alternative:
dd if=debian-live-9.5.0-amd64-cinnamon+nonfree.iso of=/dev/sdb bs=4M; sync

.B COPY USB STICK TO ANOTHER STICK BITWISE
https://superuser.com/questions/1041163/how-do-i-clone-a-usb-stick-including-partitions

dd if=/dev/source of=/dev/target bs=1M

This was used and worked fine to copy a live boot kali usb stick (version 2017.03) from /dev/sdb to /dev/sdc.
Worked fine, even though that original usb stick had two hidden partitions (by Kali Live Image).

.I ALTERNATIVE: CREATE AN IMAGE FIRST AND BURN THE IMAGE
Alternatively you could create an image first, making creation of multiple copies easier:

dd if=/dev/source of=/home/me/image.img bs=1M
dd if=/home/me/image.img of=/dev/target bs=1M

This solution was not tested by me....

------------------------------------------------------------------------------------------------------------------------
UTILS:EVENTS 
https://wiki.archlinux.org/index.php/PulseAudio/Examples#Automatically_switch_audio_to_HDMI
http://reactivated.net/writing_udev_rules.html#example-netif

You need to work with udev , systemd and shell

.I Usefull Commands 
udevadm monitor                    #will print on screen udev and kernel events (i.e wifi on/off)
udevadm info /sys/class/net/wlan0  #print information of the required device
journalctl
ls -l /lib/systemd/system 
ls -l /etc/systemd/system 
ls -l /run/systemd/system

##AUTO ENABLE HDMI SOUND WHEN HDMI IS PLUGGED IN

.B 1. create a  new rule file 
cat <<EOF > /lib/udev/rules.d/78-hdmi.rules
KERNEL=="card0", SUBSYSTEM=="drm", ACTION=="change", RUN+="/bin/systemctl start hdmi-sound.service"
EOF

PS: rule files can not call shell scripts directly
PS: systemctl path may vary. Find it using which systmctl
PS: To avoid permission issues better to copy an existed rule file: cp 78-sound.rule 78-hdmi.rules
    This will ensure that the new file will have the correct permissions. In any case all rules files seems to have 644 permissions.

.B 2. Create a .service file. Service files can call sh scripts without problem.
cat <<EOF > /etc/systemd/system/hdmi-sound.service
[Unit]
Description=hdmi sound hotplug

[Service]
Type=simple
RemainAfterExit=no
ExecStart=/usr/bin/hdmisound.sh

[Install]
WantedBy=multi-user.target

EOF

chmod 777 /etc/systemd/system/hdmi-sound.service

.B 3. Copy the file hdmisound.sh to /usr/bin
cp -iv /home/gv/Desktop/PythonTests/newpcsetup/hdmisound.sh /usr/bin

Or create this file:
cat <<EOF >/usr/bin/hdmisound.sh
sleep 0.5
    if grep '^connected$' /sys/class/drm/card0/card0-HDMI*/status ;then #/sys/class/drm/card0/*HDMI*/status >/dev/null 2>&1;then 
        sleep 2
            echo "$(date) --- HDMI connected" >> /var/log/hdmi.log #full path required
            su gv -c 'pacmd set-card-profile 0 output:hdmi-stereo' #hdmi-surround
            # Using hdmi-surround ,if you play a movie with true surround you will not hear all voices in the pc unless pc supports surround i.e have multiple speakers / channels.
            active=$(su gv -c 'pacmd list |grep "active profile"')
            echo "$(date) --- $active" >> /var/log/hdmi.log #full path required
            amixer sset 'Master' 120%  >& /dev/null

    else
        sleep 2
        echo "$(date) --- HDMI disconnected" >> /var/log/hdmi.log #full path required
        su gv -c 'pacmd set-card-profile 0 output:analog-stereo+input:analog-stereo' #pacmd does not run as root
            active=$(su gv -c 'pacmd list |grep "active profile"')
            echo "$(date) --- $active" >> /var/log/hdmi.log #full path required
            amixer sset 'Master' 120% >& /dev/null
    fi
exit 0
EOF
chmod +x /usr/bin/hdmisound.sh

.B 4. Reload rules and you are ready
udevadm control --reload-rules

.B 5. Verify that udev calls the required service using #journalctl and scroll to the end.
You should see something like this close to the end
Feb 13 02:21:16 debian systemd[1]: Configuration file /etc/systemd/system/hdmi-sound.service is marked executable. Please remove executable permission bits. Proceeding anyway.
Feb 13 02:21:16 debian systemd[1]: Configuration file /etc/systemd/system/hdmi-sound.service is marked world-writable. Please remove world writability permission bits. Proceeding anyway.
Feb 13 02:21:16 debian systemd[1]: Started hdmi sound hotplug.
Feb 13 02:21:16 debian hdmisound.sh[25807]: connected

.B 6. As an additional check you can look at the file /var/log/hdmi.log

##NETWORKING - WLAN 
http://reactivated.net/writing_udev_rules.html#example-netif

Remember that 
while inotifywait -e modify <file>;do .....;done 
does not work with /proc or /sys files.

.B Read the status:
cat /sys/class/net/wlan0/operstate 
up                                  #or down respectively. Works ok with my wifi

cat /proc/net/arp                   #grep 'wlan' /proc/net/arp
IP address       HW type     Flags       HW address            Mask     Device
192.168.1.1      0x1         0x2         f0:84:2f:70:cc:81     *        wlan0

/sbin/ethtool wlan0
Settings for wlan0:
    Link detected: yes

.HP 
.B Read status continuously on the ugly way:
#function wfcheck { 
  while :; do 
  read state </sys/class/net/wlan0/operstate; #this sys file has only one line with up/down values 
  printf "state=$state - pid=$$ -PPID=$PPID";top -b -n1 -p $$ |egrep -B1 "$$|%MEM" |awk '{printf $10 "-"}END{print " "}';
  sleep 2;done
}
# wfcheck
state=up - pid=5283 -PPID=3292-%MEM-0.1- 
state=up - pid=5283 -PPID=3292-%MEM-0.1- 
state=up - pid=5283 -PPID=3292-%MEM-0.1-

.B Execute a script if wlan is up
https://unix.stackexchange.com/questions/166473/debian-how-to-run-a-script-on-startup-as-soon-as-there-is-an-internet-connecti
cat /lib/systemd/system/NetworkManager-dispatcher.service 
cat /etc/NetworkManager/dispatcher.d/01-ifupdown           #a shell script that calls if-up / if-down scripts

Those scripts are executed if net is up, before up, down, after down, etc
#ls -l /etc/network
total 28
drwxr-xr-x 2 root root 4096 Oct 20 02:40 if-down.d
drwxr-xr-x 2 root root 4096 Oct 20 02:29 if-post-down.d
drwxr-xr-x 2 root root 4096 Sep 24 20:14 if-pre-up.d
drwxr-xr-x 2 root root 4096 Dec  4 02:37 if-up.d
-rw-r--r-- 1 root root  240 Sep 20  2016 interfaces
drwxr-xr-x 2 root root 4096 Mar 13  2015 interfaces.d
lrwxrwxrwx 1 root root   12 Sep 20  2016 run -> /run/network

.I Script example 
.B Make a script into if-up.d directory. This will be called everytime that network interface is up.
/etc/network/if-up.d# ls -l
total 24
-rwxr-xr-x 1 root root  923 Apr 13  2015 avahi-autoipd
-rwxr-xr-x 1 root root  484 Apr 13  2015 avahi-daemon
-rwxr-xr-x 1 root root 1685 Jun 30  2016 ethtool
-rwxr-xr-x 1 root root  124 Dec 15 18:49 greetme
-rwxr-xr-x 1 root root 4958 Apr  6  2015 mountnfs
lrwxrwxrwx 1 root root   32 Aug  8 23:50 wpasupplicant -> ../../wpa_supplicant/ifupdown.sh

/etc/network/if-up.d# cat greetme
#!/bin/sh
# filename: wlan-up

#if [ "$IFACE" = wlan0 ]; then
  echo "this is script greetme under if-up.d Directory.wlan0 is up"
#>>/tmp/wlantest.log
#fi
/tmp/wlantest.sh

/etc/network/if-up.d# cat /tmp/wlantest.sh
gksu -u gv 'yad --text="all good"'
echo "this is from script /tmp/wlantest.sh"

.B Run & Troubleshoot the script
Disable wifi and re-enable it to force a reconnection and force if-up.d scripts to execute.
Since i got no greeting , let's see what might goes wrong.
Run journalctl and scroll to the last lines - scroll  to the end:

/etc/network/if-up.d# journalctl
Dec 16 17:26:46 debian avahi-daemon[628]: Registering new address record for 192.168.1.121 on wlan0.IPv4.
Dec 16 17:26:46 debian NetworkManager[636]: <info>  [1544974006.7904] device (wlan0): state change: secondaries -> activated (reason 'n
Dec 16 17:26:46 debian NetworkManager[636]: <info>  [1544974006.7964] manager: NetworkManager state is now CONNECTED_LOCAL
Dec 16 17:26:46 debian NetworkManager[636]: <info>  [1544974006.8684] manager: NetworkManager state is now CONNECTED_SITE
Dec 16 17:26:46 debian NetworkManager[636]: <info>  [1544974006.8692] policy: set 'CYTA921541' (wlan0) as default for IPv4 routing and 
Dec 16 17:26:46 debian dhclient[2561]: bound to 192.168.1.121 -- renewal in 21108 seconds.
Dec 16 17:26:46 debian NetworkManager[636]: <info>  [1544974006.9268] device (wlan0): Activation: successful, device activated.
Dec 16 17:26:46 debian NetworkManager[636]: <info>  [1544974006.9283] manager: NetworkManager state is now CONNECTED_GLOBAL
Dec 16 17:26:46 debian dbus-daemon[626]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.f
Dec 16 17:26:46 debian systemd[1]: Starting Network Manager Script Dispatcher Service...
Dec 16 17:26:46 debian dbus-daemon[626]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher'
Dec 16 17:26:46 debian systemd[1]: Started Network Manager Script Dispatcher Service.
Dec 16 17:26:46 debian nm-dispatcher[2574]: req:1 'up' [wlan0]: new request (1 scripts)
Dec 16 17:26:46 debian nm-dispatcher[2574]: req:1 'up' [wlan0]: start running ordered scripts...
Dec 16 17:26:46 debian nm-dispatcher[2574]: req:2 'connectivity-change': new request (1 scripts)
Dec 16 17:26:47 debian nm-dispatcher[2574]: this is script greetme under if-up.d Directory.wlan0 is up
Dec 16 17:26:47 debian minissdpd[1014]: setsockopt(udp, IPV6_JOIN_GROUP)(FF02::C, ): Address already in use
Dec 16 17:26:47 debian minissdpd[1014]: setsockopt(udp, IPV6_JOIN_GROUP)(FF02::C, ): Address already in use
Dec 16 17:26:48 debian gksu[2615]: cannot open display: 
Dec 16 17:26:48 debian nm-dispatcher[2574]: this is from script /tmp/wlantest.sh
Dec 16 17:26:48 debian nm-dispatcher[2574]: this is script greetme under if-up.d Directory.wlan0 is up
Dec 16 17:26:48 debian gksu[2659]: cannot open display: 
Dec 16 17:26:48 debian nm-dispatcher[2574]: this is from script /tmp/wlantest.sh
Dec 16 17:26:48 debian nm-dispatcher[2574]: req:2 'connectivity-change': start running ordered scripts...

Obviously the script greetme was called by networkmanager when wlan0 was up again.
The text 'this is script greetme...." exists (twice? wtf?) and gksu reports an error related to yad, meaning that the greetme script called without problem
the script /tmp/wlantest.sh. Moreover the relevant text from /tmp/wlantest.sh is also here (this is from script /tmp....)

No clue why the greetme script run twice. Can be limited to run once using a kind of "flags" saved to a tmp file, i.e echo "hasrun=true" > /tmp/wlanhasrun

------------------------------------------------------------------------------------------------------------------------
UTILS:XORG

##XORG CONFIGURATION FILES
ls -all /usr/share/X11/xorg.conf.d/*
-rw-r--r-- 1 root root   92 Mar  7 04:44 /usr/share/X11/xorg.conf.d/10-amdgpu.conf
-rw-r--r-- 1 root root 1099 Jan 18  2017 /usr/share/X11/xorg.conf.d/10-evdev.conf
-rw-r--r-- 1 root root 1350 Jan 18 14:11 /usr/share/X11/xorg.conf.d/10-quirks.conf
-rw-r--r-- 1 root root   92 Mar  7 10:51 /usr/share/X11/xorg.conf.d/10-radeon.conf
-rw-r--r-- 1 root root  945 Sep 23 14:47 /usr/share/X11/xorg.conf.d/40-libinput.conf
-rw-r--r-- 1 root root 1175 Mar 17 05:23 /usr/share/X11/xorg.conf.d/41-evdev.conf
-rw-r--r-- 1 root root  113 Jul 14  2017 /usr/share/X11/xorg.conf.d/50-multitouch.conf
-rw-r--r-- 1 root root 1753 Nov 18  2016 /usr/share/X11/xorg.conf.d/70-synaptics.conf
-rw-r--r-- 1 root root 2747 Jun 26  2017 /usr/share/X11/xorg.conf.d/70-wacom.conf
-rw-r--r-- 1 root root  742 Sep 28  2016 /usr/share/X11/xorg.conf.d/90-touchscreen.conf

Conf files name starts with a priority number.
40-libinput.conf is loaded by xserver AFTER 10-*.conf

Files 10-evdev.conf and 40-libinput.conf affect the same input devices.
Since libinput has a higher priority, libinput driver is used but libinput sucks - evdev is much better and more configurable

For this reason i made a 'cp 10-evdev.conf 41-evdev.conf' to force evdev driver to be used in all input devices - higher priority than 40-libinput.conf

If you create/copy evdev to 99-evdev.conf then this conf will override all previously conf files including 70-synaptics.conf and will
make touchpad not to work correctly.

You can verify the driver used (evded or libinput) by xinput list-props DevId.
If evdev is used you should see properties like
Evdev Middle Button Emulation (277):    0

if libinput is used the above line will be like
libinput Middle Button Emulation (277): 0

##XINPUT
You can use xinput to see / adjust properties in all input devices

xinput list                              # list input devices
xinput list-props DevId                  # list properties of a device providing DevId as reported by xinput list
xinput set-prop DevId PropId PropValue   # set a property to Device ID. PropID could be full prop name or prop id number

example:
xinput list-props 13
Device 'SynPS/2 Synaptics TouchPad':
    Device Enabled (141):   1
    ....more options here....
    
xinput set-prop 13 141 0 ---> disables the TouchPad
xinput set-prop 13 141 1 ---> enables the TouchPad

##XORG & TOUCHSCREENS
cat /usr/share/X11/xorg.conf.d/90-touchscreen.conf
Section "InputClass"
        Identifier      "Touchscreen"
        MatchProduct    "ELAN Touchscreen"
        MatchIsTouchscreen "yes"
        Driver "evdev"
        MatchDevicePath "/dev/input/event*"
#       Option  "MinX"  "48"
#       Option  "MaxX"  "65487"
#       Option  "MinY"  "-384"
#       Option  "MaxY"  "64810"
#       Option  "SwapXY"        "0" # unless it was already set to 1
#       Option  "InvertX"       "0"  # unless it was already set
#       Option  "InvertY"       "0"  # unless it was already set
        Option "EmulateThirdButton" "1"
        Option "EmulateThirdButtonTimeout" "500"
        Option "EmulateThirdButtonThreshold" "30"
        Option "Evdev Third Button Emulation" "1"
        Option "Evdev Third Button Emulation Timeout" "550"
#/* CARD8 */
#"Evdev Third Button Emulation Button"
        Option "Evdev Third Button Emulation Threshold" "33"

EndSection

This file was created by me (using internet search) in an attempt to make touchscreen to nativelly support long press right click
It turned out that long press right click , touch screen scrolling etc, are features supported by GTK3 progs and not GTK2 progs.
As a result almost any GTK3 will support touchscreen events like scrolling : okular pdf reader, nautilus file manager, etc

Touchscreen right click by long pressing it seems that fails even in GTK3.
This can be solved with python scripting - see rightclick-gv.py & relevant rightclick python scripts 


------------------------------------------------------------------------------------------------------------------------
UTILS:NETCAT 
https://en.wikipedia.org/wiki/Netcat     # wikipedia has a lot of examples
https://gist.github.com/lenciel/8780269

Examples bellow are based on two PCs, both equipped with Debian XFCE Testing @ Latest Release (March 2018)
PC1-Toshiba : 192.168.1.116
PC2-Dell : 192.168.1.106

##INVOCATION - Simple client / server
nc     : netcat traditional tool
netcat : the usuall netcat package in modern distros like debian
ncat   : Similar tool to netcat - same principle - same switches but is not a netcat. Provided by package nmap

Server: $ netcat -l -k -p Port ---> Listening mode - awaiting connections

Client: $ netcat ip Port   --> Connects to IP at specific Port
OR
Client: echo "hello" >/dev/tcp/IP/Port  
PS: You can use a second terminal as "client" in the same machine

.I Common Options
-l : listen. As a general idea the listening machine should be started first
-p : port
-k : keep open
-s : Specify particular host to establish a connection


##SEND A FILE
PC2-Dell: netcat -l -p 8111 >somefilecopy.pdf     
# or $ netcat -l -p 8111 |cat - >somefilecopy.pdf

PC1-Toshiba: cat somefile.pdf >/dev/tcp/192.168.1.106/8111  
# or $ cat file.pdf |netcat 192.168.1.106 8111 
# or $ netcat 192.168.1.106 8111 <file.pdf 

Alternative:
PC1-Toshiba : cat somefile.pdf |netcat -l -p 8111            
#or netcat -l -p 8111 <file.pdf

PC2-Dell    : cat </dev/tcp/192.168.1.116/8111 >somecopy.pdf  
#or netcat 192.168.1.116 8111 >copy.pdf 
#or netcat 192.168.1.116 8111 |cat - >copy.pdf
Works but connection is not automatically terminated when cat is finished
You can force connection to close after inactivity by using -w 5 switch (wait 5 seconds) at netcat listening side.

##VIDEO VLC/MPV STREAMING
https://wiki.videolan.org/Uncommon_uses/

.I Method 1 - Classic Server - Client
PC1-Toshiba : $ netcat -l -p 8111 <3071-BRHD-GR-TRAGOUDA.mp4
#OR           $ cat 3071-BRHD-GR-TRAGOUDA.mp4 |netcat -l -p 8111   #server

PC2-Dell    : $ netcat 192.168.1.116 8111 |vlc -            #client
#or         : $ cat </dev/tcp/192.168.1.116/8111 |vlc - 
#or         : $ mpv <(netcat 192.168.1.116 8111)            #might not work with vlc
#Surprisingly this does not work : $ vlc </dev/tcp/192.168.1.116/8111 
#It has been proved that VLC works even directly (i.e Win VLC) by open VLC (GUI) , "Open Network Stream" -- > tcp://192.168.1.116:8111

.I Method 2 - Reversed
PC2-Dell    : $ netcat -l -p 8111 |vlc -       #Starts netcat in listening mode and vlc in stdin input mode. You might need to use -k switch also
PC1-Toshiba : $ cat 3071-BRHD-GR-TRAGOUDA.mp4 >/dev/tcp/192.168.1.106/8111
OR $ cat 3071-BRHD-GR-TRAGOUDA.mp4 |netcat 192.168.1.106 8111
OR $ netcat 192.168.1.106 8111 <3071-BRHD-GR-TRAGOUDA.mp4

##Movie Streaming with SRT File
Not tested yet but idea is to use two netcats at server at different ports.
One port will serve the movie, the other port will serve srt file
Something like this:
PC1:
netcat -l -p 8111 <mymovie.mp4
netcat -l -p 8112 <mymovie.srt

PC2:
mpv <(netcat IP MoviePort) --sub-file <(netcat IP SRTPort)

Tip: You can send the srt file from server to client and open this srt file explicitly with mpv when movie is playing.
Srt will not be autoloaded due to mismatching names of srt pipe && movie pipe

##WGET Save and watch movie
wget http://cclicence.film/myfavourite.mp4 -O- | tee myfav.mp4 | mpv - #or |mpv --sub-file=file.srt -
------------------------------------------------------------------------------------------------------------------------

UTILS:GRUB
https://wiki.debian.org/GrubEFIReinstall


##REINSTALLING GRUB
1. Check that the computer booted in computer in EFI mode:
[ -d /sys/firmware/efi ] && echo "EFI boot on HDD" || echo "Legacy boot on HDD"   --> should return "EFI boot on HDD".

2. Mount the /boot/efi if not already mounted:
mount /dev/sda1 /boot/efi

3. Reinstall the grub-efi package
apt-get install --reinstall grub-efi

4. grub-install /dev/sda

5. Re create a grub config file based on your disk partitioning schema
update-grub

6. You should check afterwards that: 
6.1 the bootloader is existing in /boot/efi/EFI/debian/grubx64.efi:
file /boot/efi/EFI/debian/grubx64.efi
--> /boot/efi/EFI/debian/grubx64.efi: PE32+ executable (EFI application) x86-64 (stripped to external PDB), for MS Windows

6.2 the nvram entry was properly created.
efibootmgr --verbose | grep debian

##GRUB - REPAIR FROM WINDOWS
.I https://itsfoss.com/no-grub-windows-linux/
When Windows apply a major update it is quite common grub to break.
In some cases , windows just replace the default boot manager entry in their own boot manager and actually grub is not showing at all, but Windows are loaded by default.

All you need is to modify bootmgr to point to /boot/efi/EFI/Debian
In windows , open a terminal as administrator and write:

bcdedit /set {bootmgr} path \EFI\debian\grubx64.efi   #tested and works 18.09.2019

To detect the correct path run:
bcdedit /enum firmware

Undo: 
bcdedit /deletevalue {bootmgr} path \EFI\debian\grubx64.efi
bcdedit /set {bootmgr} path \EFI\Microsoft\Boot\bootmgfw.efi

Non Bootable System (if above steps break the system boot manager)
See here https://itsfoss.com/no-bootable-device-found-ubuntu/
and here http://www.wavesys.com/support/cannot-boot-windows-bootable-device-not-found-error-after-initializing-drive-dell-e6x30-syst

##GRUB - BOOT IN COMMAND LINE
You can press 'e' when in grub menu and find the line including kernel parameters (usually ro quiet) and add to the end the word single.
You can also add a custom entry in the grub menu, so this CLI boot will be presented as an option by grub on your next boot.

Using single as boot parameter enters actually recovery mode and some features like network are disabled.
To bring up network you need 
$ ifconfig -a        #detect your network interface
$ ifconfig eth0 up   #bring up your interface
$ dhclient eth0      #enable dhcp client for your interface to get a valid ip. You should be ready.

##GRUB TWEAKS
find / -type f -name 'grub.cfg'   ---> /boot/grub/grub.cfg

This grub.cfg file is generated by update-grub. 
You can edit /etc/default/grub for manual finetunning like:
GRUB_DEFAULT=2     ---> Default menu entry to be auto-selected 
GRUB_TIMEOUT=5     ---> Timeout Before to load Default Entry


In one of my system i had three partitions: /dev/sda3 = Windows, /dev/sda5 = Ubuntu and /dev/sda9 = Debian
Ubuntu was installed first so the grub was actually installed by Ubuntu.
When i deleted Ubuntu partition, grub crashed.
Searching for grub.cfg returns:
# find /boot -name 'grub.cfg'
/boot/efi/EFI/ubuntu/grub.cfg
/boot/grub/grub.cfg

The file grub.cfg under /boot/grub was correct (Debian Generated) but the ubuntu/grub should be changed like this:
Original file                                                      ---> Modified File
search.fs_duuid bcd36820-8e94-4134-95ef-8b51f618d397 root hd0,gpt5  ---> search.fs_uuid 78164877-465b-408a-9c0f-3360a317fc42 root hd0,gpt9 
set prefix=($root)'/boot/grub'                                     ---> preserved and not changed
configfile $prefix/grub.cfg                                        ---> preserved and not changed

Tip: You can find UUID of all partitions with command 'blkid'
Tip: On a fresh & clean Debian , there is only one cfg file: /boot/grub/grub.cfg
Tip: The order of the menu entries in grub.cfg seems that affect the order that entries are displayed in boot menu
Though if you change the grub.cfg , the next 'grub-update' will re-create this file according to /etc/default/grub and according to configuration files present in /etc/grub.d/

In /etc/grub.d directory you can see conf files starting with a number like 10-linux. The number might denote a priority number in grub.cfg generation process by update-grub.

mkdir /mnt/usb
mount /dev/sdc /mnt/usb
mkdir /mnt/usb/boot/efi
mount /dev/sda1 /mnt/usb/boot/efi
grub-install --force --removable --boot-directory=/mnt/usb/boot /dev/sdc


##GRUB-REBOOT & GRUB-SET-DEFAULT
.I https://wiki.debian.org/GrubReboot
With the command grub-reboot you are allowed to temporary (next time only) select the grub entry that will be automatically selected in your grub menu on next reboot,
ignoring for this time the setting grub_default that is hardcoded in you grub configuration file (/boot/grub/grub.cfg)
Just provide in command line of your linux 
.B grub-reboot 0 && reboot

Now the first line of the grub menu will be selected (grub numbering starts from zero) for the next reboot only. 

This is usefull for example when your grub-default setting is for example 2 (win partition in my system) but you want to make a reboot and force grub to use entry 0 (Debian in my setup).

if you want to change the default boot item permanently you can either edit the grub.cfg file or provide this command in Linux CLI:
.B grub-set-default 0
With this command you probably don't need to run update-grub command (required when you manually edit the grub.cfg file)

##GRUB BOOT FROM COMMAND LINE (when grub crashes)
Considering that your Debian was installed at /dev/sda9 and grub has crashed badly.
You can save the day like this:

grub> ls
(hd0) (hd0,gpt9) etc

grub> insmod ext2
grub> set root='(hd0,gpt9)'
grub> ls /
....various real files that you used to see in your root directory....
grub> linux /vmlinuz root=/dev/sda9 ro quiet  ---> if ok no output returns. Ommitting root=/dev/sda9 leads to Kernel Panic
grub> initrd /initrd.img                      ---> if ok no output returns
grub> boot                                    ---> if ok starts booting

Tip: 
In Debian the most recent kernel and initrd image is found under root as symlinks, with names 'vmlinuz' and 'initrd.img'
This is why /vmlinuz works above.

If you want to specify a particular kernel (i.e a legacy 3.14 kernel) then you can use something like linux /boot/vmlinuz-of-your-choice.
Accordingly it is mandatory to load the initrd that matches the kernel version you loaded before: /boot/initrd-matching-vmlinuz-choice.img

Tip: 
You can still call the grub CLI even if grub works ok by following grub menu on-screen instructions.
You might need this tweak in case you want to manually load a kernel from a usb (/dev/sdb or /dev/sdc) as a workaround if usb auto-boot was not succesfull for some reason.

##FSTAB
To ensure that booting will be ok you need a working /etc/fstab file like this:
# /etc/fstab: static file system information.
#
# Use 'blkid' to print the universally unique identifier for a
# device; this may be used with UUID= as a more robust way to name devices
# that works even if disks are added and removed. See fstab(5).
#
# <file system> <mount point>   <type>  <options>       <dump>  <pass>
# / was on /dev/sda9 during installation
UUID=78164877-465b-408a-9c0f-3360a317fc42 /               ext4    errors=remount-ro 0       1
# /boot/efi was on /dev/sda1 during installation
UUID=F665-1803  /boot/efi       vfat    umask=0077      0       1
# swap was on /dev/sda8 during installation
UUID=3278b9af-f992-4ab8-8fe5-7d20bef6ce43 none            swap    sw              0       0


##FSTAB - AUTOMOUNT DRIVE / PARTITION
https://superuser.com/questions/646249/automatically-mount-a-2nd-hard-drive-in-debian-7

Partition /dev/sda3 holds my Windows. You can automount this partition like this:
1. umount /dev/sda3
2. mkdir /media/MyWin 
3. blkid ---> find the /dev/sda3 UUID
4. Add to /etc/fstab the following line
UUID=A25866FE5866D119 /media/MyWin ntfs defaults 0 0
5. mount -a

------------------------------------------------------------------------------------------------------------------------
UTILS:NETWORKING
##FORTICLIENT VPN - OPENFORTI
openfortivpn is a free vpn client that can be connected to Fortinet.
apt install openfortivpn

You need to manually configure the following file:
nano /etc/openfortivpn/config
host = ipadressofserver
port = serverort
username = yourname
password = yourpassword
trusted-cert = e4........................................ce5

The last line (trusted-cert) is not known the very first time you run openfortivpn
After the first run (/usr/bin/openfortivpn) you will be prompted to include this trusted-cert in your openforti configuration file.

If everything is set up correctly you should see:
root@debian:/home/gv# openfortivpn
INFO:   Connected to gateway.
Two-factor authentication token: 
INFO:   Authenticated.
INFO:   Remote gateway has allocated a VPN.
INFO:   Got addresses: [10.10.10.1], ns [172.20.199.16, 172.20.199.17]
INFO:   negotiation complete
INFO:   negotiation complete
INFO:   Interface ppp0 is UP.
INFO:   Setting new routes...
INFO:   Adding VPN nameservers...
INFO:   Tunnel is up and running.
PS: To close the connection press ctrl+c
^CINFO:   Cancelling threads...
INFO:   Setting ppp interface down.
INFO:   Restoring routes...
INFO:   Removing VPN nameservers...
INFO:   pppd: The link was terminated by the modem hanging up.
INFO:   Terminated pppd.
INFO:   Closed connection to gateway.
INFO:   Logged out.


Once connected to vpn, routing should have changed automatically to drive all traffic to vpn tunnel:
root@debian:/home/gv# ip route show
default dev ppp0 scope link 
169.254.0.0/16 dev wlan0 scope link metric 1000 
192.0.2.1 dev ppp0 proto kernel scope link src 10.10.10.1 
192.168.1.0/24 dev wlan0 proto kernel scope link src 192.168.1.120 metric 600 
195.167.101.170 via 192.168.1.1 dev wlan0 

Before vpn , routing was different. First line (default dev) was pointing to wlan0:
default via 192.168.1.1 dev wlan0 metric 1535 
169.254.0.0/16 dev wlan0 scope link metric 1000 
192.168.1.0/24 dev wlan0 proto kernel scope link src 192.168.1.120 metric 600 

Verify vpn connectivity using ping to a valid - known remote IP/server on the vpn side.

##ACCESSING WINDOWS NETWORK LOCATION THROUGH VPN FROM DEBIAN
https://www.howtogeek.com/176471/how-to-share-files-between-windows-and-linux/

.B Accessing a windows shared location by Debian
gv@debian:~$ mkdir ~/Desktop/Windows-Share
gv@debian:~$ sudo mount.cifs //10.5.1.50/H_users/Common /home/gv/Desktop/Windows-Share -o user=ge.vasiliou
Password for ge.vasiliou@//10.5.1.50/H_users/Common:  *********
OK, Now just open the Windows-Share folder like any folder in your pc.

Tips: 
Obiously you need first to establish a valid vpn connection to the remote server
Better to use IP instead of domain names to be sure that you talk to the correct server.
Remember that a local server with name i.e alpha, accessed locally in windows with \\alpha, should be accessed remotely using \\alpha.domainname.local
Also remember that linux doesn't like \\ , but loves // 
Avoid to use root account when you mount.cifs to be capable to open the sharre as normal user.

##DOWNLOAD A FILE FROM WINDOWS SHARED LOCATION USING DEBIAN
gv@debian:~$ sudo smbget --user=gv --workgroup=domainname.local smb://10.1.7.12/Users/Drawings/file640.pdf
Prompts for password, and as soon as you have permissions in the shared folder, pdf file is downloaded normally.

##SHARE A FOLDER OR DRIVE OR PARTITION FROM DEBIAN TO WINDOWS (LAN)
https://www.howtogeek.com/176471/how-to-share-files-between-windows-and-linux/
Tip Date: 2022
Scenario: You Debian PC is up and running inside the lan. You want to be able to share over lan a folder , or even an external HDD

.B Setting At Host (Debian) Machine
Step 1: make sure that you have samba installed on your debian (samba server and maybe samba client - 
.I apt-get install samba
In some files managers like gnome, nautilus, etc you can just right click a folder and share it , as easy as is done on Windowns.
On XFCE you have to do some command line actions to assign a shared folder.

Step 2: Open samba configuration file and create manually the shares you want like this (add bellow to the end of file)
.I geany /etc/samba/smb.conf

[natwin]
   comment = natwin-debian
   path = /media/MyWin/Documents and Settings/nat/
   valid users = gv
   available = yes
   browseable = yes
   public = yes
   writeable = yes
   read only = no
   guest ok = no

The name in [ ] is the name that your share will appear on shared directories when browsed by other machines.
PS: Don't try to access your share with the comment name!
Save the file and close your editor.

Step 3: In order the share to work , you need to add samba users with this command from CLI:
.I smbpasswd -a geek
#This will add user geek at samba environment
#If you have already add a user before (i.e for a previous share) you don't need to add a new user again, unless you want to.

Step 4: Now, you just need to restart the SMB service for the changes to take effect : 
.I sudo service smbd restart

.B Settings at Guest (Windows) PC that will access the Debian PC Shares
Step 5: 
Open the network location of the shared folder with Win File Explore with this syntax: \\IP-ADDRESS\SHARE-NAME
In our case 
.I \\192.168.xxx.xxx\natwin

You can try to create a shortcut pointing to the above address , or Add Network Location (right click on My Computer/This PC).
Those techniques failed in my business laptop on the first share (assigned to a domain), but worked on my second external HDD share

Step 6: 
The only technique that really worked is Map Network Drive (Right Click on MyPC in Win10) providing the above path.
You need alsot to select "Connect Using Different Credentials".
When propmted for different credentials provide:
Username : .\geek (mind the .\ to define that this user is a local user and not a domain user).
Tip: You need to click on "more settings - different account" to be able to use different user name (.\geek)

Password : The password provided at Debian for samba user geek
For some reason my laptop asks for the credentials password a second time, having already username and password completed (geek & asterisks). 
You just hit enter and the process proceeds.

Tip:
On my second share attempt (external HDD atttached to Debian) i did not changed the prompted user by Win10 dialogues 
I kept the user that Win10 prompted: myWin10-business-domain-name\sambashare-username-on-debian 
and i just entered the correct debian samba password two times and workd fine.

In my case this technique worked and allowed me to share a single Debian desktop folder to lan, or even a mounted location under the hdd of Debian i.e a Windows Partition).
On my second share, i was able to browse my external HDD attached to Debian at location /media/XXX/myHDD

Tip:
I did a lot of failed attempts just to realize that in step6 (map network drive) i was giving the wrong share name.
Instead of \\192.168.xxx.xxx\sambasharename (i.e \mypassport) i was trying to connect to \\192.168.xxx.xxx\sambashare-comment

Tip: 
It is known that Win10 has stopped to support smb1 shares - I enabled smb1 sharing support by Windows Features Turn on/off at control panel (scroll down and look for smb1)

 
------------------------------------------------------------------------------------------------------------------------
UTILS:CRYPTOGRAPHY

##HIDE DATA IN IMAGES
There are tools that can be used to hide data or texts or even a whole image within another image (hat's off to Jolanda)
Such programs are:
* steghide
* binwalk

------------------------------------------------------------------------------------------------------------------------
UTILS:TEAMVIEWER
Updated: 22/11/2020

##INSTALL WITH APT
First check if your repos already have teamviewer available; if yes just apt-get install
$apt list 'teamview*'

On Kali for example, teamviewer is missing. Follow these steps:
$ echo "deb http://linux.teamviewer.com/deb stable main" | sudo tee /etc/apt/sources.list.d/teamviewer.list
$ apt-get update #error comes up due to missing teamviewer GPG key
$ apt-get install gpg ca-certificates
$ apt-key adv --keyserver ha.pool.sks-keyservers.net --recv-keys C5E224500C1289C0  #use the key that apt-get advised
$ apt list 'teamviewer*'
Listing... Done
teamviewer-host/stable 15.11.6 amd64
teamviewer-monitoring/stable 1.0.166669 amd64
teamviewer/stable 15.11.6 amd64
$ apt install teamviewer
#was installed correctly in my kali machine

##TEAMVIEWER UPDATE
Normally, a teamviewer.list file will be added in /etc/apt/sources.list.d directory during teamviewer installation.
This file contains this basic line:
deb https://linux.teamviewer.com/deb stable main

The teamviewer repository can be controlled by command line like this:
teamviewer repo                - show current repository configuration
teamviewer repo default        - restore default configuration
teamviewer repo disable        - disable the repository
teamviewer repo stable         - make all regular TeamViewer packages available (default)
teamviewer repo preview        - additionally, make feature preview packages available
teamviewer repo development    - additionally, make the latest development packages available


------------------------------------------------------------------------------------------------------------------------
UTILS:GOOGLE CHROME
Updated: 22/11/2020

##INSTALL in KALI MANUALLY
If google chrome is not available in repos (like in kali) then:
$ wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
$ apt-get install ./google-chrome-stable_current_amd64.deb   # apt-get install is preferable than dkpg -i , since it installs also dependencies
$ google-chrome --no-sandbox   
#google chrome does not run as root (defaul user for kali is root) unless --no-sandbox flag is given , but better to create a simple user with adduser command
#for debian that you are loged in as standard user, you don't need --no-sandbox flag.

During the installation the following file will be created inside sources.list.d directory, to allow future updates

$ cat /etc/apt/sources.list.d/google-chrome.list
### THIS FILE IS AUTOMATICALLY CONFIGURED ###
# You may comment out this entry, but any other modifications may be lost.
deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main

.B Chrome Installation Trick:
You can create the .list file manually with nano/echo/etcetera and then run apt-get update && apt-get install google-chrome-stable 
apt-get update reads the repos in /etc/apt/sources.list and /etc/apt/sources.list.d directory, so by supplying the web location of google chrome apt-get will be capable to 
locate the google-chrome package (apt-get update) and then you can install it with apt-get install

------------------------------------------------------------------------------------------------------------------------
UTILS:ZOOM
Updated: 22/11/2020
https://computingforgeeks.com/how-to-install-zoom-client-on-kali-linux/

##INSTALL in KALI MANUALLY
$ wget https://zoom.us/client/latest/zoom_amd64.deb
$ apt-get install ./zoom_amd64.deb
# installs a lot of dependencies, but seems to work ok

------------------------------------------------------------------------------------------------------------------------
UTILS:PROXY
##INSTALL SQUID PROXY ON DEBIAN
Date: 29.03.2022
Follow the instruction provided here:
.I https://linuxize.com/post/how-to-install-and-configure-squid-proxy-on-debian-10/

.B Squid Configuration
After installation on my Debian 11 , i only adjusted proxy port. 
By default, Squid listens on port 3128 on all network interfaces. 
I changed listen port and all rest setting files remained at default values.

Keep a back up of the original conf file:
.I sudo cp /etc/squid/squid.conf{,.orginal}

Tips:
The Access Control Lists (ACLs) allows you to control how the clients can access web resources. 
By default, Squid allows access only from the localhost.

.B My Current & Working Squid Configuration:
root:#cat -n /etc/squid/squid.conf |grep -v '^\s*[0-9]*\s*[#]\|^\s*[0-9]*\s*$'
  1188	acl localnet src 0.0.0.1-0.255.255.255	# RFC 1122 "this" network (LAN)
  1189	acl localnet src 10.0.0.0/8		# RFC 1918 local private network (LAN)
  1190	acl localnet src 100.64.0.0/10		# RFC 6598 shared address space (CGN)
  1191	acl localnet src 169.254.0.0/16 	# RFC 3927 link-local (directly plugged) machines
  1192	acl localnet src 172.16.0.0/12		# RFC 1918 local private network (LAN)
  1193	acl localnet src 192.168.0.0/16		# RFC 1918 local private network (LAN)
  1194	acl localnet src fc00::/7       	# RFC 4193 local private network range
  1195	acl localnet src fe80::/10      	# RFC 4291 link-local (directly plugged) machines
  1197	acl SSL_ports port 443
  1198	acl Safe_ports port 80		# http
  1199	acl Safe_ports port 21		# ftp
  1200	acl Safe_ports port 443		# https
  1201	acl Safe_ports port 70		# gopher
  1202	acl Safe_ports port 210		# wais
  1203	acl Safe_ports port 1025-65535	# unregistered ports
  1204	acl Safe_ports port 280		# http-mgmt
  1205	acl Safe_ports port 488		# gss-http
  1206	acl Safe_ports port 591		# filemaker
  1207	acl Safe_ports port 777		# multiling http
  1208	acl CONNECT method CONNECT
  1385	http_access deny !Safe_ports
  1388	http_access deny CONNECT !SSL_ports
  1391	http_access allow localhost manager
  1392	http_access deny manager
  1402	include /etc/squid/conf.d/*
  1408	http_access allow localhost
  1411	http_access deny all
  1907	http_port 8000
  4571	coredump_dir /var/spool/squid
  5272	refresh_pattern ^ftp:		1440	20%	10080
  5273	refresh_pattern ^gopher:	1440	0%	1440
  5274	refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
  5275	refresh_pattern .		0	20%	4320

root:# cat /etc/squid/conf.d/debian.conf
#
# Squid configuration settings for Debian
#

# Logs are managed by logrotate on Debian
logfile_rotate 0

# For extra security Debian packages only allow
# localhost to use the proxy on new installs
#
# Bellow line if disabled (tried at 29.03.2022) makes squid proxy to stop working in the lan
http_access allow localnet

.B Allow - Deny certain lan IPs
Edit /etc/squid/squid.conf
acl allowed_ips  src "/etc/squid/allowed_ips.txt"
http_access allow localhost
http_access allow allowed_ips
# And finally deny all other access to this proxy
http_access deny all

PS1: Obviously the access is read serially - the deny all last command does not affect the previous allow commands.
PS2: allowed_ips.txt is a single txt file , containing a list of allowed IPs i.e 192.158.1.10 , etc (one IP per line)

.B Squid status - restart - etc
service squid status #or systemctl status squid
service squid restart #or systemctl restart squid

.B Using squid
In Chrome (Win) just go to setting and provide the lan ip that squids is running to
In Chrome (Lin) you have to run chrome like this:
.I /usr/bin/google-chrome --user-data-dir="$HOME/proxy-profile" --proxy-server="http://SQUID_IP:3128"

.B Squid Logs
Logs are found in path /var/log/squid
.I tail -5 /var/log/squid/access.log
Returns the 5 last (end) entries. Date in the beginning is provided in epoch time.

.I tail -20 /var/log/squid/access.log |awk '{cmd="date -d@"$1;cmd |getline $1; close(cmd)}1'
.I tail -20 /var/log/squid/access.log |awk '{$1=strftime("%c",$1)}1'
Uses awk to print the last (more recent) log entries, converting date from epoch to normal date format

##Windows LAN Proxy Servers 
Date 21.06.2022
.B https://www.filehorse.com/download-ccproxy/
CC Proxy installed with a GUI, runs easily but:
Make sure that the proxy port you select is not in use by other ports. Using 8080 seems a good choice.
In my setup i had to change default IP available in each setting from 0.0.0.0 to the PC IP that proxy server runs on (192.168.x.x)
Make sure that the proxy port 8080 is open on the firewall available in the local machine you installed ccproxy
I suceed to open firewall door in my corporate - quite stric - laptop by adding a firewall rule allowing any protocol, all ports.
And surprisingly , this new port adding was working ok.

Keep in mind that if you installed ccproxy in a corporate PC that admin policies apply to restrict your internet connection (black lists, web filtering, etc)
then ccproxy will adopt those restrictions.... meaning that you can not bypass the admin rules just because you installed a proxy.

.B https://www.wingate.com/
Not tested. 

.B https://softradar.com/freeproxy/
Not Tested.

.B Chrome addon UltraSurf Security, Privacy & Unblock VPN
You can add it in chrome , should be handled as extension, and once enabled it uses some proxies in the background (or even vpn - not clear) to bypass admin restrictions and allow you to visit blocked pages.
Important: We don't know how Ultrasurf handles our data (passwords, bank accounts, etc). We don't know if those data are kept somewhere without us knowing that.
I used UltraSurf (and worked like a charm) to be able to access whatsapp web & github website - those were blocked by my corporate admin in my business laptop....
